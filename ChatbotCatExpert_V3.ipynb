{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final ChatBot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation of Pakages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pytube\n",
    "%pip install --upgrade pytube\n",
    "%pip install yt-dlp\n",
    "%pip install moviepy\n",
    "%pip install whisper\n",
    "%pip install chromadb sentence-transformers\n",
    "%pip install git+https://github.com/openai/whisper.git\n",
    "%pip install pytubefix\n",
    "%pip install chromadb\n",
    "%pip install langchain\n",
    "%pip install openai\n",
    "%pip install opencv-python\n",
    "%pip install langchain_openai\n",
    "%pip install --upgrade huggingface_hub\n",
    "%pip install --upgrade sentence-transformers\n",
    "%pip install langchain_community\n",
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import langsmith\n",
    "\n",
    "# Specify the path to the .env file\n",
    "dotenv_path = \"./notebooks/apikey.env\" #Change if your env is in a diffretn folder\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Ensure required environment variables are loaded\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "# Check if all environment variables are set; raise an error if any are missing\n",
    "if not all([OPENAI_API_KEY, LANGCHAIN_API_KEY, HUGGINGFACEHUB_API_TOKEN]):\n",
    "    raise ValueError(\"Some required API keys are missing in the .env file.\")\n",
    "\n",
    "# Enable LangSmith tracing with environment variables\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"cat_expert_knowledge\"\n",
    "\n",
    "# Initialize LangSmith Client\n",
    "from langsmith import Client\n",
    "client = Client(api_key=LANGCHAIN_API_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import yt_dlp\n",
    "import whisper\n",
    "import chromadb\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import gradio as gr\n",
    "import asyncio\n",
    "from pytubefix import YouTube\n",
    "import hashlib\n",
    "import uuid\n",
    "\n",
    "\n",
    "# Load OpenAI API key\n",
    "\n",
    "# Cat name memory storage with a limit of 3\n",
    "cat_name_memory = []\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Whisper model initialization for transcription\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "# ChromaDB initialization for vector storage\n",
    "chroma_client = chromadb.Client()\n",
    "try:\n",
    "    chroma_collection = chroma_client.create_collection(name=\"jackson_galaxy_videos\")\n",
    "except chromadb.errors.UniqueConstraintError:\n",
    "    chroma_collection = chroma_client.get_collection(name=\"jackson_galaxy_videos\")\n",
    "\n",
    "# Define the directories for audio and transcriptions\n",
    "audio_dir = \"/notebooks/path/to/m4a\"\n",
    "transcription_dir = \"/notebooks/path/to/transcriptions\"\n",
    "os.makedirs(audio_dir, exist_ok=True)  # Ensure the audio directory exists\n",
    "os.makedirs(transcription_dir, exist_ok=True)  # Ensure the transcription directory exists\n",
    "\n",
    "# List of YouTube URLs\n",
    "video_urls = [\n",
    "    \"https://youtu.be/ZUcVUFvmDFE?si=z9GfOAWF1qothiKs\",\n",
    "    \"https://youtu.be/4DlJYcfiRu4?si=cUVT9L5dEEdkcSt_\",\n",
    "    \"https://youtu.be/rxInrRQLEmM?si=Ai7wHN0dI--cns0x\",\n",
    "    \"https://youtu.be/gxlNfh5ukMw?si=naO3n4VZeXx3PlOs\",\n",
    "    \"https://youtu.be/ojS7XwtoXtw?si=NpNSef7dCm_LnFPv\",\n",
    "    \"https://youtu.be/tsYT7yIOdqQ?si=hdGEpxlmFNMf7NNQ\",\n",
    "    \"https://youtu.be/tsYT7yIOdqQ?si=e_Zdh2dGpqempHR8\",\n",
    "    \"https://youtu.be/UWohxDOXsl4?si=y1nXlUZYw6uzkc8n\",\n",
    "    \"https://youtu.be/gZrwcoiy_gY?si=ksfYE03t6xtuxUL0\",\n",
    "    \"https://youtu.be/lSDI5diNu4Y?si=Q-In6zMD4ZpuaPIz\",\n",
    "    \"https://youtu.be/8aCGL9GpVUg?si=_0yF1U1thjwJqyPY\",\n",
    "    \"https://youtu.be/VjOXvD7OvrE?si=t6xugNxLeMjpsi7E\",\n",
    "    \"https://youtu.be/FzifwTnCV5s?si=sR_u4kG-4NoQx5Ux\",\n",
    "    \"https://youtu.be/XreeFU7RYeI?si=hsc9WO24dJP6AfV2\",\n",
    "    \"https://youtu.be/-4O97jw_8Bc?si=pC14dgZ_f4mXdYPv\"\n",
    "]\n",
    "\n",
    "# Function to create a unique filename from URL\n",
    "def generate_filename(url, extension=\"m4a\"):\n",
    "    \"\"\"Creates a unique filename for each URL based on its hash.\"\"\"\n",
    "    return hashlib.md5(url.encode()).hexdigest() + f\".{extension}\"\n",
    "\n",
    "# Download each video as audio and handle errors\n",
    "failed_downloads = []  # To log any failed downloads\n",
    "\n",
    "for url in video_urls:\n",
    "    # Generate filename and check if it exists\n",
    "    filename = generate_filename(url)\n",
    "    file_path = os.path.join(audio_dir, filename)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Already downloaded: {url}\")\n",
    "        continue  # Skip downloading if file exists\n",
    "    \n",
    "    # Download video if not already downloaded\n",
    "    try:\n",
    "        yt = YouTube(url)\n",
    "        video = yt.streams.filter(only_audio=True).first()\n",
    "        video.download(output_path=audio_dir, filename=filename)\n",
    "        print(f\"Downloaded: {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n",
    "        failed_downloads.append(url)\n",
    "\n",
    "# Optional: log failed downloads if any\n",
    "if failed_downloads:\n",
    "    print(\"Failed Downloads:\", failed_downloads)\n",
    "    # You could write these to a log file for later review\n",
    "\n",
    "# Step 1: Video Transcription Using Whisper (Updated)\n",
    "# Directory containing your .m4a files\n",
    "audio_files = [f for f in os.listdir(audio_dir) if f.endswith(\".m4a\")]\n",
    "\n",
    "# Transcribe each audio file and save it as a .txt file, only if the transcription doesn't already exist\n",
    "for audio_file in audio_files:\n",
    "    audio_path = os.path.join(audio_dir, audio_file)\n",
    "    transcription_filename = os.path.join(transcription_dir, audio_file.replace(\".m4a\", \".txt\"))\n",
    "    \n",
    "    # Skip transcription if the file already exists\n",
    "    if os.path.exists(transcription_filename):\n",
    "        print(f\"Already transcribed: {transcription_filename}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        transcription = whisper_model.transcribe(audio_path)\n",
    "        \n",
    "        # Save transcription to file\n",
    "        with open(transcription_filename, \"w\") as f:\n",
    "            f.write(transcription['text'])\n",
    "        print(f\"Transcribed and saved: {transcription_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to transcribe {audio_file}: {e}\")\n",
    "\n",
    "# Step 2: Add Transcription to ChromaDB\n",
    "def add_to_chromadb(transcription, metadata):\n",
    "    embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "    vector = embedding_model.embed_documents([transcription])[0]\n",
    "    unique_id = str(uuid.uuid4())  # Generate a unique ID for each document\n",
    "    chroma_collection.add(ids=[unique_id], documents=[transcription], metadatas=[{\"source\": metadata}], embeddings=[vector])\n",
    "\n",
    "# Read all transcriptions from .txt files and add to ChromaDB, only if not already added\n",
    "existing_ids = [metadata['source'] for metadata in chroma_collection.get()['metadatas']] if chroma_collection.count() > 0 else []\n",
    "\n",
    "for url in video_urls:\n",
    "    filename = generate_filename(url)\n",
    "    transcription_path = os.path.join(transcription_dir, filename.replace(\".m4a\", \".txt\"))\n",
    "    if os.path.exists(transcription_path) and url not in existing_ids:\n",
    "        with open(transcription_path, \"r\") as f:\n",
    "            transcription = f.read()\n",
    "        add_to_chromadb(transcription, url)\n",
    "\n",
    "# Step 3: Retrieval-Augmented Generation (RAG) Pipeline (Updated to use Local Transcriptions)\n",
    "first_time_greeting = True\n",
    "\n",
    "def generate_response(query):\n",
    "    global first_time_greeting\n",
    "    if first_time_greeting:\n",
    "        first_time_greeting = False\n",
    "        return \"What's up my loving cat people! How can I assist you today?\"\n",
    "    \n",
    "    # Ensure the conversation history limit is maintained to avoid overflow\n",
    "    if len(cat_name_memory) > 3:\n",
    "        cat_name_memory.pop(0)\n",
    "    # Extract cat's name if mentioned in the query\n",
    "    cat_name = None\n",
    "    match = re.search(r\"my cat named ([A-Za-z]+)\", query, re.IGNORECASE)\n",
    "    if match:\n",
    "        cat_name = match.group(1)\n",
    "        if cat_name not in cat_name_memory:\n",
    "            cat_name_memory.append(cat_name)\n",
    "        if len(cat_name_memory) > 3:\n",
    "            cat_name_memory.pop(0)\n",
    "    elif cat_name_memory:\n",
    "        cat_name = cat_name_memory[-1]\n",
    "    embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "    vectordb = Chroma(embedding_function=embedding_model, collection_name=\"jackson_galaxy_videos\", client=chroma_client)\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})  # Limit the number of retrieved documents to avoid context overflow\n",
    "\n",
    "    # Enhanced prompt to request more detailed and specific responses in Jackson Galaxy's tone.\n",
    "    if cat_name:\n",
    "        personalized_message = f\"Regarding your cat named {cat_name}, \"\n",
    "    else:\n",
    "        personalized_message = \"\"\n",
    "\n",
    "    prompt = (personalized_message +\n",
    "        f\"As Jackson Galaxy, respond to the following question with empathy, expertise, charisma and detailed advice. Be informative and consider practical tips to help the cat owner understand their cat better:\\n\"\n",
    "        f\"Question: {query}\\n\"\n",
    "        f\"Advice:\"\n",
    "    )\n",
    "\n",
    "    # Use the adjusted prompt\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo\", max_tokens=800),\n",
    "        retriever=retriever,\n",
    "        chain_type=\"map_reduce\"\n",
    "        #chain_type=\"refine\"\n",
    "    )\n",
    "    response = qa_chain.run(prompt).strip()  # Stripping whitespace for cleaner output\n",
    "\n",
    "    return f\"{response} Remember, understanding your cat is key to improving your bond!\"\n",
    "\n",
    "# Step 4: Using LangChain Agents to Automate Workflow (Updated)\n",
    "def setup_agents():\n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"Generate Response\",\n",
    "            func=generate_response,\n",
    "            description=\"Use this to generate responses based on transcriptions using RAG\"\n",
    "        )\n",
    "    ]\n",
    "    llm = ChatOpenAI(temperature=0.7, openai_api_key=OPENAI_API_KEY)\n",
    "    agent = initialize_agent(tools, llm, agent_type=\"zero-shot-react-description\", verbose=True)\n",
    "    return agent\n",
    "\n",
    "agent = setup_agents()\n",
    "\n",
    "# Gradio Interface for User Interaction\n",
    "def ask_question_gradio(question):\n",
    "    if len(question.strip()) == 0:\n",
    "        return \"Please ask a proper question about your cat.\"\n",
    "    try:\n",
    "            response = asyncio.run(asyncio.to_thread(agent.run, question))\n",
    "            return response\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "iface = gr.Interface(fn=ask_question_gradio, inputs=\"text\", outputs=\"text\", title=\"Jackson Galaxy Chatbot\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Launch Gradio interface\n",
    "    iface.launch(share=True)\n",
    "\n",
    "V3.1 Remebers the cat name but crashes."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
