{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pytube\n",
    "%pip install --upgrade pytube\n",
    "%pip install yt-dlp\n",
    "%pip install moviepy\n",
    "%pip install whisper\n",
    "%pip install chromadb sentence-transformers\n",
    "%pip install git+https://github.com/openai/whisper.git\n",
    "%pip install pytubefix\n",
    "%pip install chromadb\n",
    "%pip install langchain\n",
    "%pip install openai\n",
    "%pip install opencv-python\n",
    "%pip install langchain_openai\n",
    "%pip install --upgrade huggingface_hub\n",
    "%pip install --upgrade sentence-transformers\n",
    "%pip install langchain_community\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import langsmith\n",
    "\n",
    "# Specify the path to the .env file\n",
    "dotenv_path = \"./notebooks/apikey.env\" #Change if your env is in a diffretn folder\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Ensure required environment variables are loaded\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "# Check if all environment variables are set; raise an error if any are missing\n",
    "if not all([OPENAI_API_KEY, LANGCHAIN_API_KEY, HUGGINGFACEHUB_API_TOKEN]):\n",
    "    raise ValueError(\"Some required API keys are missing in the .env file.\")\n",
    "\n",
    "# Enable LangSmith tracing with environment variables\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"cat_expert_knowledge\"\n",
    "\n",
    "# Initialize LangSmith Client\n",
    "from langsmith import Client\n",
    "client = Client(api_key=LANGCHAIN_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded: https://youtu.be/ZUcVUFvmDFE?si=z9GfOAWF1qothiKs\n",
      "Already downloaded: https://youtu.be/4DlJYcfiRu4?si=cUVT9L5dEEdkcSt_\n",
      "Already downloaded: https://youtu.be/rxInrRQLEmM?si=Ai7wHN0dI--cns0x\n",
      "Already downloaded: https://youtu.be/gxlNfh5ukMw?si=naO3n4VZeXx3PlOs\n",
      "Already downloaded: https://youtu.be/ojS7XwtoXtw?si=NpNSef7dCm_LnFPv\n",
      "Already downloaded: https://youtu.be/tsYT7yIOdqQ?si=hdGEpxlmFNMf7NNQ\n",
      "Already downloaded: https://youtu.be/tsYT7yIOdqQ?si=e_Zdh2dGpqempHR8\n",
      "Already downloaded: https://youtu.be/UWohxDOXsl4?si=y1nXlUZYw6uzkc8n\n",
      "Already downloaded: https://youtu.be/gZrwcoiy_gY?si=ksfYE03t6xtuxUL0\n",
      "Already downloaded: https://youtu.be/lSDI5diNu4Y?si=Q-In6zMD4ZpuaPIz\n",
      "Already downloaded: https://youtu.be/8aCGL9GpVUg?si=_0yF1U1thjwJqyPY\n",
      "Already downloaded: https://youtu.be/VjOXvD7OvrE?si=t6xugNxLeMjpsi7E\n",
      "Already downloaded: https://youtu.be/FzifwTnCV5s?si=sR_u4kG-4NoQx5Ux\n",
      "Already downloaded: https://youtu.be/XreeFU7RYeI?si=hsc9WO24dJP6AfV2\n",
      "Already downloaded: https://youtu.be/-4O97jw_8Bc?si=pC14dgZ_f4mXdYPv\n",
      "Already transcribed: /notebooks/path/to/transcriptions/c4181c7e744aaaae5aaf7e234e39a17e.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/c813c650315977e7da699c0b2d52799d.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/When Cat Introductions Get UGLY.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/6e43a9a97ff958b094ee86b59d6fa433.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/Can my Cats Get Along? Cat-to-Cat Body Language basics & Introduction Tips.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/How To Introduce Your Cat to a New KITTEN!.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/How to Introduce Cats.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/Are My Cats Playing or Fighting? | Cat Playing vs Cat Aggression.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/Cat Introductions Gone Wrong: They Will NOT Work it Out Without You.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/55340c0bd9e5d16b88d7bdc38908eccc.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/14744c59f76c5a6fb10402ccdd3e280e.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/4c4c7f472299b10d74dee0ecdc941b3b.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/This was BAD!! ðŸ™€ðŸ¤¯ðŸ«£ #shorts.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/f72adde394a4d4b403421fd7bb5324fb.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/The Do's & Don'ts of Introducing Cats.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/0ad0281d64cf5d1e366881ec6adfbd9f.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/b81b63d4601ef135d3641d91fa8e5920.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/Cat Introductions: Good First Impressions are a must!.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/The Best Way To Introduce Your Two Cats.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/Cat Introductions: Does your Senior Need A Friend?.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/89438d05ab80fbaad4194f97dcf8f786.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/de747e570a36df03149fca7596d7686e.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/Why You Should Get Another Cat.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/Can Cats & Dogs Be Friends? | Jackson Galaxy.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/fa8c74567ee31f6e4bdfc0abb681f0a4.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/55f9f04d946d68dcac4bff1b1292a8c5.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/Brady Bunching: Introducing Two Groups of Cats.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/f6d781840478116e21403e46776c5d21.txt\n",
      "Already transcribed: /notebooks/path/to/transcriptions/23e9e0c657974c427119ed6e734c704d.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1030/900210842.py:146: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0.7, openai_api_key=OPENAI_API_KEY)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7879\n",
      "* Running on public URL: https://45bc8d57bf37cae4c3.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://45bc8d57bf37cae4c3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the tool to generate a response based on transcriptions related to bathing cats.\n",
      "Action: Generate Response\n",
      "Action Input: Can I give my cat a bath?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAs Jackson Galaxy, here's my advice: I don't know, but generally, cats are known for grooming themselves and do not require regular baths like dogs do. If your cat gets into something that requires cleaning, it's usually best to use cat-safe wipes or consult with a veterinarian for guidance on bathing your cat. Remember, understanding your cat is key to improving your bond!\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe response suggests that cats generally do not need regular baths and it's best to consult with a veterinarian for guidance.\n",
      "Final Answer: It's best to consult with a veterinarian for guidance on bathing your cat.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yt_dlp\n",
    "import whisper\n",
    "import chromadb\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import gradio as gr\n",
    "import asyncio\n",
    "from pytubefix import YouTube\n",
    "import hashlib\n",
    "import uuid\n",
    "\n",
    "# Load OpenAI API key\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Whisper model initialization for transcription\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "# ChromaDB initialization for vector storage\n",
    "chroma_client = chromadb.Client()\n",
    "try:\n",
    "    chroma_collection = chroma_client.create_collection(name=\"jackson_galaxy_videos\")\n",
    "except chromadb.errors.UniqueConstraintError:\n",
    "    chroma_collection = chroma_client.get_collection(name=\"jackson_galaxy_videos\")\n",
    "\n",
    "# Define the directories for audio and transcriptions\n",
    "audio_dir = \"/notebooks/path/to/m4a\"\n",
    "transcription_dir = \"/notebooks/path/to/transcriptions\"\n",
    "os.makedirs(audio_dir, exist_ok=True)  # Ensure the audio directory exists\n",
    "os.makedirs(transcription_dir, exist_ok=True)  # Ensure the transcription directory exists\n",
    "\n",
    "# List of YouTube URLs\n",
    "video_urls = [\n",
    "    \"https://youtu.be/ZUcVUFvmDFE?si=z9GfOAWF1qothiKs\",\n",
    "    \"https://youtu.be/4DlJYcfiRu4?si=cUVT9L5dEEdkcSt_\",\n",
    "    \"https://youtu.be/rxInrRQLEmM?si=Ai7wHN0dI--cns0x\",\n",
    "    \"https://youtu.be/gxlNfh5ukMw?si=naO3n4VZeXx3PlOs\",\n",
    "    \"https://youtu.be/ojS7XwtoXtw?si=NpNSef7dCm_LnFPv\",\n",
    "    \"https://youtu.be/tsYT7yIOdqQ?si=hdGEpxlmFNMf7NNQ\",\n",
    "    \"https://youtu.be/tsYT7yIOdqQ?si=e_Zdh2dGpqempHR8\",\n",
    "    \"https://youtu.be/UWohxDOXsl4?si=y1nXlUZYw6uzkc8n\",\n",
    "    \"https://youtu.be/gZrwcoiy_gY?si=ksfYE03t6xtuxUL0\",\n",
    "    \"https://youtu.be/lSDI5diNu4Y?si=Q-In6zMD4ZpuaPIz\",\n",
    "    \"https://youtu.be/8aCGL9GpVUg?si=_0yF1U1thjwJqyPY\",\n",
    "    \"https://youtu.be/VjOXvD7OvrE?si=t6xugNxLeMjpsi7E\",\n",
    "    \"https://youtu.be/FzifwTnCV5s?si=sR_u4kG-4NoQx5Ux\",\n",
    "    \"https://youtu.be/XreeFU7RYeI?si=hsc9WO24dJP6AfV2\",\n",
    "    \"https://youtu.be/-4O97jw_8Bc?si=pC14dgZ_f4mXdYPv\"\n",
    "]\n",
    "\n",
    "# Function to create a unique filename from URL\n",
    "def generate_filename(url, extension=\"m4a\"):\n",
    "    \"\"\"Creates a unique filename for each URL based on its hash.\"\"\"\n",
    "    return hashlib.md5(url.encode()).hexdigest() + f\".{extension}\"\n",
    "\n",
    "# Download each video as audio and handle errors\n",
    "failed_downloads = []  # To log any failed downloads\n",
    "\n",
    "for url in video_urls:\n",
    "    # Generate filename and check if it exists\n",
    "    filename = generate_filename(url)\n",
    "    file_path = os.path.join(audio_dir, filename)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Already downloaded: {url}\")\n",
    "        continue  # Skip downloading if file exists\n",
    "    \n",
    "    # Download video if not already downloaded\n",
    "    try:\n",
    "        yt = YouTube(url)\n",
    "        video = yt.streams.filter(only_audio=True).first()\n",
    "        video.download(output_path=audio_dir, filename=filename)\n",
    "        print(f\"Downloaded: {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n",
    "        failed_downloads.append(url)\n",
    "\n",
    "# Optional: log failed downloads if any\n",
    "if failed_downloads:\n",
    "    print(\"Failed Downloads:\", failed_downloads)\n",
    "    # You could write these to a log file for later review\n",
    "\n",
    "# Step 1: Video Transcription Using Whisper (Updated)\n",
    "# Directory containing your .m4a files\n",
    "audio_files = [f for f in os.listdir(audio_dir) if f.endswith(\".m4a\")]\n",
    "\n",
    "# Transcribe each audio file and save it as a .txt file, only if the transcription doesn't already exist\n",
    "for audio_file in audio_files:\n",
    "    audio_path = os.path.join(audio_dir, audio_file)\n",
    "    transcription_filename = os.path.join(transcription_dir, audio_file.replace(\".m4a\", \".txt\"))\n",
    "    \n",
    "    # Skip transcription if the file already exists\n",
    "    if os.path.exists(transcription_filename):\n",
    "        print(f\"Already transcribed: {transcription_filename}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        transcription = whisper_model.transcribe(audio_path)\n",
    "        \n",
    "        # Save transcription to file\n",
    "        with open(transcription_filename, \"w\") as f:\n",
    "            f.write(transcription['text'])\n",
    "        print(f\"Transcribed and saved: {transcription_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to transcribe {audio_file}: {e}\")\n",
    "\n",
    "# Step 2: Add Transcription to ChromaDB\n",
    "def add_to_chromadb(transcription, metadata):\n",
    "    embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "    vector = embedding_model.embed_documents([transcription])[0]\n",
    "    unique_id = str(uuid.uuid4())  # Generate a unique ID for each document\n",
    "    chroma_collection.add(ids=[unique_id], documents=[transcription], metadatas=[{\"source\": metadata}], embeddings=[vector])\n",
    "\n",
    "# Read all transcriptions from .txt files and add to ChromaDB, only if not already added\n",
    "existing_ids = [metadata['source'] for metadata in chroma_collection.get()['metadatas']] if chroma_collection.count() > 0 else []\n",
    "\n",
    "for url in video_urls:\n",
    "    filename = generate_filename(url)\n",
    "    transcription_path = os.path.join(transcription_dir, filename.replace(\".m4a\", \".txt\"))\n",
    "    if os.path.exists(transcription_path) and url not in existing_ids:\n",
    "        with open(transcription_path, \"r\") as f:\n",
    "            transcription = f.read()\n",
    "        add_to_chromadb(transcription, url)\n",
    "\n",
    "# Step 3: Retrieval-Augmented Generation (RAG) Pipeline (Updated to use Local Transcriptions)\n",
    "def generate_response(query):\n",
    "    embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "    vectordb = Chroma(embedding_function=embedding_model, collection_name=\"jackson_galaxy_videos\", client=chroma_client)\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})  # Limit the number of retrieved documents to avoid context overflow\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm=ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo\", max_tokens=250), retriever=retriever, chain_type=\"stuff\")\n",
    "    response = qa_chain.run(query)\n",
    "    return f\"As Jackson Galaxy, here's my advice: {response} Remember, understanding your cat is key to improving your bond!\"\n",
    "\n",
    "# Step 4: Using LangChain Agents to Automate Workflow (Updated)\n",
    "def setup_agents():\n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"Generate Response\",\n",
    "            func=generate_response,\n",
    "            description=\"Use this to generate responses based on transcriptions using RAG\"\n",
    "        )\n",
    "    ]\n",
    "    llm = ChatOpenAI(temperature=0.7, openai_api_key=OPENAI_API_KEY)\n",
    "    agent = initialize_agent(tools, llm, agent_type=\"zero-shot-react-description\", verbose=True)\n",
    "    return agent\n",
    "\n",
    "agent = setup_agents()\n",
    "\n",
    "# Gradio Interface for User Interaction\n",
    "def ask_question_gradio(question):\n",
    "    response = asyncio.run(asyncio.to_thread(agent.run, f\"Generate Response: {question}\"))\n",
    "    return response\n",
    "\n",
    "iface = gr.Interface(fn=ask_question_gradio, inputs=\"text\", outputs=\"text\", title=\"Jackson Galaxy Chatbot\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Launch Gradio interface\n",
    "    iface.launch(share = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
