{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatChat bot V.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pytube\n",
    "#%pip install --upgrade pytube\n",
    "#%pip install yt-dlp\n",
    "#%pip install moviepy\n",
    "#%pip install whisper\n",
    "#%pip install chromadb sentence-transformers\n",
    "#%pip install git+https://github.com/openai/whisper.git\n",
    "#%pip install pytubefix\n",
    "#%pip install chromadb\n",
    "#%pip install langchain\n",
    "#%pip install openai\n",
    "#%pip install opencv-python\n",
    "#%pip install langchain_openai\n",
    "#%pip install --upgrade huggingface_hub\n",
    "#%pip install --upgrade sentence-transformers\n",
    "#%pip install langchain_community\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import langsmith\n",
    "\n",
    "# Specify the path to the .env file\n",
    "dotenv_path = \"apikey.env\" #Change if your env is in a diffretn folder\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Ensure required environment variables are loaded\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "# Check if all environment variables are set; raise an error if any are missing\n",
    "if not all([OPENAI_API_KEY, LANGCHAIN_API_KEY, HUGGINGFACEHUB_API_TOKEN]):\n",
    "    raise ValueError(\"Some required API keys are missing in the .env file.\")\n",
    "\n",
    "# Enable LangSmith tracing with environment variables\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"cat_expert_knowledge\"\n",
    "\n",
    "# Initialize LangSmith Client\n",
    "from langsmith import Client\n",
    "client = Client(api_key=LANGCHAIN_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: https://youtu.be/ZUcVUFvmDFE?si=z9GfOAWF1qothiKs\n",
      "Downloaded: https://youtu.be/4DlJYcfiRu4?si=cUVT9L5dEEdkcSt_\n",
      "Downloaded: https://youtu.be/rxInrRQLEmM?si=Ai7wHN0dI--cns0x\n",
      "Downloaded: https://youtu.be/gxlNfh5ukMw?si=naO3n4VZeXx3PlOs\n",
      "Downloaded: https://youtu.be/ojS7XwtoXtw?si=NpNSef7dCm_LnFPv\n",
      "Downloaded: https://youtu.be/tsYT7yIOdqQ?si=hdGEpxlmFNMf7NNQ\n",
      "Downloaded: https://youtu.be/tsYT7yIOdqQ?si=e_Zdh2dGpqempHR8\n",
      "Downloaded: https://youtu.be/UWohxDOXsl4?si=y1nXlUZYw6uzkc8n\n",
      "Downloaded: https://youtu.be/gZrwcoiy_gY?si=ksfYE03t6xtuxUL0\n",
      "Downloaded: https://youtu.be/lSDI5diNu4Y?si=Q-In6zMD4ZpuaPIz\n",
      "Downloaded: https://youtu.be/8aCGL9GpVUg?si=_0yF1U1thjwJqyPY\n",
      "Downloaded: https://youtu.be/VjOXvD7OvrE?si=t6xugNxLeMjpsi7E\n",
      "Downloaded: https://youtu.be/FzifwTnCV5s?si=sR_u4kG-4NoQx5Ux\n",
      "Downloaded: https://youtu.be/XreeFU7RYeI?si=hsc9WO24dJP6AfV2\n",
      "Downloaded: https://youtu.be/-4O97jw_8Bc?si=pC14dgZ_f4mXdYPv\n"
     ]
    }
   ],
   "source": [
    "from pytubefix import YouTube\n",
    "import os\n",
    "import hashlib\n",
    "\n",
    "# Define the directory for downloaded audio files\n",
    "output_path = \"/1_Lab_Final_Proyect/Chatbot-dump\"\n",
    "os.makedirs(output_path, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "# Replace with your list of YouTube URLs\n",
    "video_urls = [\"https://youtu.be/ZUcVUFvmDFE?si=z9GfOAWF1qothiKs\", \n",
    "            \"https://youtu.be/4DlJYcfiRu4?si=cUVT9L5dEEdkcSt_\", \n",
    "            \"https://youtu.be/rxInrRQLEmM?si=Ai7wHN0dI--cns0x\", \n",
    "            \"https://youtu.be/gxlNfh5ukMw?si=naO3n4VZeXx3PlOs\", \n",
    "            \"https://youtu.be/ojS7XwtoXtw?si=NpNSef7dCm_LnFPv\", \n",
    "            \"https://youtu.be/tsYT7yIOdqQ?si=hdGEpxlmFNMf7NNQ\", \n",
    "            \"https://youtu.be/tsYT7yIOdqQ?si=e_Zdh2dGpqempHR8\", \n",
    "            \"https://youtu.be/UWohxDOXsl4?si=y1nXlUZYw6uzkc8n\", \n",
    "            \"https://youtu.be/gZrwcoiy_gY?si=ksfYE03t6xtuxUL0\", \n",
    "            \"https://youtu.be/lSDI5diNu4Y?si=Q-In6zMD4ZpuaPIz\", \n",
    "            \"https://youtu.be/8aCGL9GpVUg?si=_0yF1U1thjwJqyPY\", \n",
    "            \"https://youtu.be/VjOXvD7OvrE?si=t6xugNxLeMjpsi7E\", \n",
    "            \"https://youtu.be/FzifwTnCV5s?si=sR_u4kG-4NoQx5Ux\", \n",
    "            \"https://youtu.be/XreeFU7RYeI?si=hsc9WO24dJP6AfV2\", \n",
    "            \"https://youtu.be/-4O97jw_8Bc?si=pC14dgZ_f4mXdYPv\" ]\n",
    "\n",
    "# Function to create a unique filename from URL\n",
    "def generate_filename(url, extension=\"m4a\"):\n",
    "    \"\"\"Creates a unique filename for each URL based on its hash.\"\"\"\n",
    "    return hashlib.md5(url.encode()).hexdigest() + f\".{extension}\"\n",
    "\n",
    "# Download each video as audio and handle errors\n",
    "failed_downloads = []  # To log any failed downloads\n",
    "\n",
    "for url in video_urls:\n",
    "    # Generate filename and check if it exists\n",
    "    filename = generate_filename(url)\n",
    "    file_path = os.path.join(output_path, filename)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Already downloaded: {url}\")\n",
    "        continue  # Skip downloading if file exists\n",
    "    \n",
    "    # Download video if not already downloaded\n",
    "    try:\n",
    "        yt = YouTube(url)\n",
    "        video = yt.streams.filter(only_audio=True).first()\n",
    "        video.download(output_path=output_path, filename=filename)\n",
    "        print(f\"Downloaded: {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n",
    "        failed_downloads.append(url)\n",
    "\n",
    "# Optional: log failed downloads if any\n",
    "if failed_downloads:\n",
    "    print(\"Failed Downloads:\", failed_downloads)\n",
    "    # You could write these to a log file for later review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcriptions done by Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:10<00:00, 13.3MiB/s]\n",
      "C:\\Users\\diego\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "C:\\Users\\diego\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to transcribe 0ad0281d64cf5d1e366881ec6adfbd9f.m4a: [WinError 2] The system cannot find the file specified\n",
      "Failed to transcribe 14744c59f76c5a6fb10402ccdd3e280e.m4a: [WinError 2] The system cannot find the file specified\n",
      "Failed to transcribe 23e9e0c657974c427119ed6e734c704d.m4a: [WinError 2] The system cannot find the file specified\n",
      "Failed to transcribe 4c4c7f472299b10d74dee0ecdc941b3b.m4a: [WinError 2] The system cannot find the file specified\n",
      "Failed to transcribe 55340c0bd9e5d16b88d7bdc38908eccc.m4a: [WinError 2] The system cannot find the file specified\n",
      "Failed to transcribe 55f9f04d946d68dcac4bff1b1292a8c5.m4a: [WinError 2] The system cannot find the file specified\n",
      "Failed to transcribe 6e43a9a97ff958b094ee86b59d6fa433.m4a: [WinError 2] The system cannot find the file specified\n",
      "Failed to transcribe 89438d05ab80fbaad4194f97dcf8f786.m4a: [WinError 2] The system cannot find the file specified\n",
      "Failed to transcribe b81b63d4601ef135d3641d91fa8e5920.m4a: [WinError 2] The system cannot find the file specified\n",
      "Failed to transcribe c4181c7e744aaaae5aaf7e234e39a17e.m4a: [WinError 2] The system cannot find the file specified\n",
      "Failed to transcribe c813c650315977e7da699c0b2d52799d.m4a: [WinError 2] The system cannot find the file specified\n",
      "Failed to transcribe de747e570a36df03149fca7596d7686e.m4a: [WinError 2] The system cannot find the file specified\n",
      "Failed to transcribe f6d781840478116e21403e46776c5d21.m4a: [WinError 2] The system cannot find the file specified\n",
      "Failed to transcribe f72adde394a4d4b403421fd7bb5324fb.m4a: [WinError 2] The system cannot find the file specified\n",
      "Failed to transcribe fa8c74567ee31f6e4bdfc0abb681f0a4.m4a: [WinError 2] The system cannot find the file specified\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Directory containing your .m4a files\n",
    "audio_dir = \"/1_Lab_Final_Proyect/Chatbot-dump\"\n",
    "transcription_dir = \"/1_Lab_Final_Proyect/Chatbot-dump/Transcriptions\"\n",
    "\n",
    "# Ensure the transcription directory exists\n",
    "os.makedirs(transcription_dir, exist_ok=True)\n",
    "\n",
    "# List all .m4a files in the audio directory\n",
    "audio_files = [f for f in os.listdir(audio_dir) if f.endswith(\".m4a\")]\n",
    "\n",
    "# Transcribe each audio file and save it as a .txt file\n",
    "for audio_file in audio_files:\n",
    "    audio_path = os.path.join(audio_dir, audio_file)\n",
    "    try:\n",
    "        transcription = model.transcribe(audio_path)\n",
    "\n",
    "        # Save transcription to a .txt file\n",
    "        \n",
    "        transcription_file = os.path.join(transcription_dir, audio_file.replace(\".m4a\", \".txt\"))\n",
    "        with open(transcription_file, \"w\") as f:\n",
    "            f.write(transcription['text'])\n",
    "        print(f\"Transcribed and saved: {transcription_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to transcribe {audio_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if the transcriptions are on the right path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transcription directory path/to/transcriptions does not exist.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the directory for transcription files\n",
    "transcription_dir = \"path/to/transcriptions\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(transcription_dir):\n",
    "    print(f\"The transcription directory {transcription_dir} does not exist.\")\n",
    "else:\n",
    "    # List transcription files\n",
    "    transcription_files = glob.glob(os.path.join(transcription_dir, \"*.txt\"))\n",
    "    if not transcription_files:\n",
    "        print(f\"No .txt transcription files found in {transcription_dir}.\")\n",
    "    else:\n",
    "        print(f\"Found transcription files: {transcription_files}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
