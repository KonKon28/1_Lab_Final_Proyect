{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat Chat Bot Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation command\n",
    "%pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pytube\n",
    "%pip install --upgrade pytube\n",
    "%pip install yt-dlp\n",
    "%pip install moviepy\n",
    "%pip install whisper\n",
    "%pip install chromadb sentence-transformers\n",
    "%pip install git+https://github.com/openai/whisper.git\n",
    "%pip install pytubefix\n",
    "%pip install chromadb\n",
    "%pip install langchain\n",
    "%pip install openai\n",
    "%pip install opencv-python\n",
    "%pip install langchain_openai\n",
    "%pip install --upgrade huggingface_hub\n",
    "%pip install --upgrade sentence-transformers\n",
    "%pip install langchain_community\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import langsmith\n",
    "\n",
    "# Specify the path to the .env file\n",
    "dotenv_path = \"./notebooks/apikey.env\" #Change if your env is in a diffretn folder\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Ensure required environment variables are loaded\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "# Check if all environment variables are set; raise an error if any are missing\n",
    "if not all([OPENAI_API_KEY, LANGCHAIN_API_KEY, HUGGINGFACEHUB_API_TOKEN]):\n",
    "    raise ValueError(\"Some required API keys are missing in the .env file.\")\n",
    "\n",
    "# Enable LangSmith tracing with environment variables\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"cat_expert_knowledge\"\n",
    "\n",
    "# Initialize LangSmith Client\n",
    "from langsmith import Client\n",
    "client = Client(api_key=LANGCHAIN_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/notebooks'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (LANGCHAIN_API_KEY)\n",
    "import os\n",
    "os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the videos to learn.\n",
    "Video to Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded: https://youtu.be/ZUcVUFvmDFE?si=z9GfOAWF1qothiKs\n",
      "Already downloaded: https://youtu.be/4DlJYcfiRu4?si=cUVT9L5dEEdkcSt_\n",
      "Already downloaded: https://youtu.be/rxInrRQLEmM?si=Ai7wHN0dI--cns0x\n",
      "Already downloaded: https://youtu.be/gxlNfh5ukMw?si=naO3n4VZeXx3PlOs\n",
      "Already downloaded: https://youtu.be/ojS7XwtoXtw?si=NpNSef7dCm_LnFPv\n",
      "Already downloaded: https://youtu.be/tsYT7yIOdqQ?si=hdGEpxlmFNMf7NNQ\n",
      "Already downloaded: https://youtu.be/tsYT7yIOdqQ?si=e_Zdh2dGpqempHR8\n",
      "Already downloaded: https://youtu.be/UWohxDOXsl4?si=y1nXlUZYw6uzkc8n\n",
      "Already downloaded: https://youtu.be/gZrwcoiy_gY?si=ksfYE03t6xtuxUL0\n",
      "Already downloaded: https://youtu.be/lSDI5diNu4Y?si=Q-In6zMD4ZpuaPIz\n",
      "Already downloaded: https://youtu.be/8aCGL9GpVUg?si=_0yF1U1thjwJqyPY\n",
      "Already downloaded: https://youtu.be/VjOXvD7OvrE?si=t6xugNxLeMjpsi7E\n",
      "Already downloaded: https://youtu.be/FzifwTnCV5s?si=sR_u4kG-4NoQx5Ux\n",
      "Already downloaded: https://youtu.be/XreeFU7RYeI?si=hsc9WO24dJP6AfV2\n",
      "Already downloaded: https://youtu.be/-4O97jw_8Bc?si=pC14dgZ_f4mXdYPv\n"
     ]
    }
   ],
   "source": [
    "from pytubefix import YouTube\n",
    "import os\n",
    "import hashlib\n",
    "\n",
    "# Define the directory for downloaded audio files\n",
    "output_path = \"path/to/m4a\"\n",
    "os.makedirs(output_path, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "# Replace with your list of YouTube URLs\n",
    "video_urls = [\"https://youtu.be/ZUcVUFvmDFE?si=z9GfOAWF1qothiKs\", \n",
    "            \"https://youtu.be/4DlJYcfiRu4?si=cUVT9L5dEEdkcSt_\", \n",
    "            \"https://youtu.be/rxInrRQLEmM?si=Ai7wHN0dI--cns0x\", \n",
    "            \"https://youtu.be/gxlNfh5ukMw?si=naO3n4VZeXx3PlOs\", \n",
    "            \"https://youtu.be/ojS7XwtoXtw?si=NpNSef7dCm_LnFPv\", \n",
    "            \"https://youtu.be/tsYT7yIOdqQ?si=hdGEpxlmFNMf7NNQ\", \n",
    "            \"https://youtu.be/tsYT7yIOdqQ?si=e_Zdh2dGpqempHR8\", \n",
    "            \"https://youtu.be/UWohxDOXsl4?si=y1nXlUZYw6uzkc8n\", \n",
    "            \"https://youtu.be/gZrwcoiy_gY?si=ksfYE03t6xtuxUL0\", \n",
    "            \"https://youtu.be/lSDI5diNu4Y?si=Q-In6zMD4ZpuaPIz\", \n",
    "            \"https://youtu.be/8aCGL9GpVUg?si=_0yF1U1thjwJqyPY\", \n",
    "            \"https://youtu.be/VjOXvD7OvrE?si=t6xugNxLeMjpsi7E\", \n",
    "            \"https://youtu.be/FzifwTnCV5s?si=sR_u4kG-4NoQx5Ux\", \n",
    "            \"https://youtu.be/XreeFU7RYeI?si=hsc9WO24dJP6AfV2\", \n",
    "            \"https://youtu.be/-4O97jw_8Bc?si=pC14dgZ_f4mXdYPv\" ]\n",
    "\n",
    "# Function to create a unique filename from URL\n",
    "def generate_filename(url, extension=\"m4a\"):\n",
    "    \"\"\"Creates a unique filename for each URL based on its hash.\"\"\"\n",
    "    return hashlib.md5(url.encode()).hexdigest() + f\".{extension}\"\n",
    "\n",
    "# Download each video as audio and handle errors\n",
    "failed_downloads = []  # To log any failed downloads\n",
    "\n",
    "for url in video_urls:\n",
    "    # Generate filename and check if it exists\n",
    "    filename = generate_filename(url)\n",
    "    file_path = os.path.join(output_path, filename)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Already downloaded: {url}\")\n",
    "        continue  # Skip downloading if file exists\n",
    "    \n",
    "    # Download video if not already downloaded\n",
    "    try:\n",
    "        yt = YouTube(url)\n",
    "        video = yt.streams.filter(only_audio=True).first()\n",
    "        video.download(output_path=output_path, filename=filename)\n",
    "        print(f\"Downloaded: {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n",
    "        failed_downloads.append(url)\n",
    "\n",
    "# Optional: log failed downloads if any\n",
    "if failed_downloads:\n",
    "    print(\"Failed Downloads:\", failed_downloads)\n",
    "    # You could write these to a log file for later review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcriptions done by Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribed and saved: /notebooks/path/to/transcriptions/c4181c7e744aaaae5aaf7e234e39a17e.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/c813c650315977e7da699c0b2d52799d.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/When Cat Introductions Get UGLY.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/6e43a9a97ff958b094ee86b59d6fa433.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/Can my Cats Get Along? Cat-to-Cat Body Language basics & Introduction Tips.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/How To Introduce Your Cat to a New KITTEN!.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/How to Introduce Cats.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/Are My Cats Playing or Fighting? | Cat Playing vs Cat Aggression.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/Cat Introductions Gone Wrong: They Will NOT Work it Out Without You.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/55340c0bd9e5d16b88d7bdc38908eccc.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/14744c59f76c5a6fb10402ccdd3e280e.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/4c4c7f472299b10d74dee0ecdc941b3b.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/This was BAD!! ðŸ™€ðŸ¤¯ðŸ«£ #shorts.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/f72adde394a4d4b403421fd7bb5324fb.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/The Do's & Don'ts of Introducing Cats.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/0ad0281d64cf5d1e366881ec6adfbd9f.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/b81b63d4601ef135d3641d91fa8e5920.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/Cat Introductions: Good First Impressions are a must!.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/The Best Way To Introduce Your Two Cats.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/Cat Introductions: Does your Senior Need A Friend?.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/89438d05ab80fbaad4194f97dcf8f786.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/de747e570a36df03149fca7596d7686e.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/Why You Should Get Another Cat.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/Can Cats & Dogs Be Friends? | Jackson Galaxy.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/fa8c74567ee31f6e4bdfc0abb681f0a4.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/55f9f04d946d68dcac4bff1b1292a8c5.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/Brady Bunching: Introducing Two Groups of Cats.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/f6d781840478116e21403e46776c5d21.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/23e9e0c657974c427119ed6e734c704d.txt\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Directory containing your .m4a files\n",
    "audio_dir = \"/notebooks/path/to/m4a\"\n",
    "transcription_dir = \"/notebooks/path/to/transcriptions\"\n",
    "\n",
    "# Ensure the transcription directory exists\n",
    "os.makedirs(transcription_dir, exist_ok=True)\n",
    "\n",
    "# List all .m4a files in the audio directory\n",
    "audio_files = [f for f in os.listdir(audio_dir) if f.endswith(\".m4a\")]\n",
    "\n",
    "# Transcribe each audio file and save it as a .txt file\n",
    "for audio_file in audio_files:\n",
    "    audio_path = os.path.join(audio_dir, audio_file)\n",
    "    try:\n",
    "        transcription = model.transcribe(audio_path)\n",
    "\n",
    "        # Save transcription to a .txt file\n",
    "        \n",
    "        transcription_file = os.path.join(transcription_dir, audio_file.replace(\".m4a\", \".txt\"))\n",
    "        with open(transcription_file, \"w\") as f:\n",
    "            f.write(transcription['text'])\n",
    "        print(f\"Transcribed and saved: {transcription_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to transcribe {audio_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if the transcriptions are on the right path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found transcription files: [\"path/to/transcriptions/The Do's & Don'ts of Introducing Cats.txt\", 'path/to/transcriptions/c813c650315977e7da699c0b2d52799d.txt', 'path/to/transcriptions/55340c0bd9e5d16b88d7bdc38908eccc.txt', 'path/to/transcriptions/Can my Cats Get Along? Cat-to-Cat Body Language basics & Introduction Tips.txt', 'path/to/transcriptions/When Cat Introductions Get UGLY.txt', 'path/to/transcriptions/c4181c7e744aaaae5aaf7e234e39a17e.txt', 'path/to/transcriptions/fa8c74567ee31f6e4bdfc0abb681f0a4.txt', 'path/to/transcriptions/Brady Bunching: Introducing Two Groups of Cats.txt', 'path/to/transcriptions/Can Cats & Dogs Be Friends? | Jackson Galaxy.txt', 'path/to/transcriptions/b81b63d4601ef135d3641d91fa8e5920.txt', 'path/to/transcriptions/6e43a9a97ff958b094ee86b59d6fa433.txt', 'path/to/transcriptions/Cat Introductions: Good First Impressions are a must!.txt', 'path/to/transcriptions/How to Introduce Cats.txt', 'path/to/transcriptions/This was BAD!! ðŸ™€ðŸ¤¯ðŸ«£ #shorts.txt', 'path/to/transcriptions/f6d781840478116e21403e46776c5d21.txt', 'path/to/transcriptions/14744c59f76c5a6fb10402ccdd3e280e.txt', 'path/to/transcriptions/89438d05ab80fbaad4194f97dcf8f786.txt', 'path/to/transcriptions/0ad0281d64cf5d1e366881ec6adfbd9f.txt', 'path/to/transcriptions/The Best Way To Introduce Your Two Cats.txt', 'path/to/transcriptions/Cat Introductions: Does your Senior Need A Friend?.txt', 'path/to/transcriptions/23e9e0c657974c427119ed6e734c704d.txt', 'path/to/transcriptions/de747e570a36df03149fca7596d7686e.txt', 'path/to/transcriptions/4c4c7f472299b10d74dee0ecdc941b3b.txt', 'path/to/transcriptions/f72adde394a4d4b403421fd7bb5324fb.txt', 'path/to/transcriptions/Why You Should Get Another Cat.txt', 'path/to/transcriptions/How To Introduce Your Cat to a New KITTEN!.txt', 'path/to/transcriptions/55f9f04d946d68dcac4bff1b1292a8c5.txt', 'path/to/transcriptions/Are My Cats Playing or Fighting? | Cat Playing vs Cat Aggression.txt', 'path/to/transcriptions/Cat Introductions Gone Wrong: They Will NOT Work it Out Without You.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the directory for transcription files\n",
    "transcription_dir = \"path/to/transcriptions\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(transcription_dir):\n",
    "    print(f\"The transcription directory {transcription_dir} does not exist.\")\n",
    "else:\n",
    "    # List transcription files\n",
    "    transcription_files = glob.glob(os.path.join(transcription_dir, \"*.txt\"))\n",
    "    if not transcription_files:\n",
    "        print(f\"No .txt transcription files found in {transcription_dir}.\")\n",
    "    else:\n",
    "        print(f\"Found transcription files: {transcription_files}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chromadb as Client and creation of Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chromadb as Client and creation of Collection\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import glob\n",
    "import hashlib\n",
    "\n",
    "# Initialize ChromaDB client and set up the collection\n",
    "client = chromadb.Client()\n",
    "\n",
    "\n",
    "\n",
    "# Check if the collection exists; create if not\n",
    "collection_name = \"cat_expert_knowledge\"\n",
    "if collection_name not in [col.name for col in client.list_collections()]:\n",
    "    collection = client.create_collection(collection_name)\n",
    "else:\n",
    "    collection = client.get_collection(collection_name)\n",
    "    print(f\"Using existing collection: {collection_name}\")\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#Creation of vectordb\n",
    "persist_directory = \"path/to/vectordb\"\n",
    "vectordb = Chroma.from_texts(\n",
    "        texts=splits, \n",
    "        embedding=embedding_model,\n",
    "        persist_directory=persist_directory,\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "\n",
    "\n",
    "# Directory containing transcription files\n",
    "transcription_dir = \"path/to/transcriptions\"\n",
    "\n",
    "def generate_document_id(text):\n",
    "    \"\"\"Generate a unique hash ID for each document based on its text content.\"\"\"\n",
    "    return hashlib.md5(text.encode()).hexdigest()\n",
    "\n",
    "def add_document_to_chromadb(file_path, collection):\n",
    "    \"\"\"Adds a document to ChromaDB if it doesn't already exist.\"\"\"\n",
    "    # Read file content\n",
    "    with open(file_path, \"r\") as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # Generate a unique ID based on document content\n",
    "    doc_id = generate_document_id(text)\n",
    "    \n",
    "    # Query to check if this document hash already exists\n",
    "    existing_docs = collection.query(\n",
    "        query_texts=[doc_id], \n",
    "        where={\"topic\": doc_id}\n",
    "    )\n",
    "    if existing_docs['documents']:  # If results found, skip adding\n",
    "        print(f\"Document with ID {doc_id} already exists in ChromaDB. Skipping.\")\n",
    "        return\n",
    "    \n",
    "    # Embed the text and add to ChromaDB\n",
    "    embedding = embedding_model.encode(text).tolist()\n",
    "    collection.add(\n",
    "        ids=[doc_id],\n",
    "        documents=[text],\n",
    "        metadatas=[{\"topic\": doc_id, \"source\": file_path}],\n",
    "        embeddings=[embedding]\n",
    "    )\n",
    "    print(f\"Document {doc_id} added to ChromaDB.\")\n",
    "\n",
    "# Process each transcription file\n",
    "transcription_files = glob.glob(os.path.join(transcription_dir, \"*.txt\"))\n",
    "if not transcription_files:\n",
    "    print(\"No transcription files found in the specified directory.\")\n",
    "\n",
    "for transcription_file in transcription_files:\n",
    "    try:\n",
    "        add_document_to_chromadb(transcription_file, collection)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to add {transcription_file} to ChromaDB: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# chat completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.0\n",
    ")\n",
    "# conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=5,\n",
    "    return_messages=True\n",
    ")\n",
    "# retrieval qa chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chunks: 1\n",
      "First Chunk: Your long transcription text goes here...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Download NLTK data files (only the first time)\n",
    "nltk.download('punkt')\n",
    "\n",
    "def split_text_into_chunks(text, max_length=500):\n",
    "    \"\"\"\n",
    "    Split text into smaller chunks of approximately max_length characters.\n",
    "    Uses sentence tokenization to avoid breaking sentences.\n",
    "    \n",
    "    Parameters:\n",
    "    - text: The full text to be split.\n",
    "    - max_length: The maximum length of each chunk.\n",
    "    \n",
    "    Returns:\n",
    "    - List of text chunks.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) <= max_length:\n",
    "            current_chunk += \" \" + sentence\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence\n",
    "\n",
    "    if current_chunk:  # Add any remaining text as the last chunk\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Example Usage\n",
    "transcription_text = \"Your long transcription text goes here...\"\n",
    "splits = split_text_into_chunks(transcription_text)\n",
    "print(\"Number of Chunks:\", len(splits))\n",
    "print(\"First Chunk:\", splits[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transcriptions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you have all your transcriptions in a list called `transcriptions`\u001b[39;00m\n\u001b[1;32m      2\u001b[0m all_splits \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transcription \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtranscriptions\u001b[49m:\n\u001b[1;32m      5\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m split_text_into_chunks(transcription)\n\u001b[1;32m      6\u001b[0m     all_splits\u001b[38;5;241m.\u001b[39mextend(chunks)  \u001b[38;5;66;03m# Collect all chunks\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transcriptions' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have all your transcriptions in a list called `transcriptions`\n",
    "all_splits = []\n",
    "\n",
    "for transcription in transcriptions:\n",
    "    chunks = split_text_into_chunks(transcription)\n",
    "    all_splits.extend(chunks)  # Collect all chunks\n",
    "\n",
    "# Create or load the Chroma VectorDB\n",
    "persist_directory = \"path/to/vectordb\"\n",
    "collection_name = \"cat_expert_knowledge\"\n",
    "\n",
    "if os.path.exists(persist_directory):\n",
    "    # Load the existing VectorDB if it exists\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=embedding_model.encode,\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "    print(\"Loaded existing VectorDB from:\", persist_directory)\n",
    "else:\n",
    "    # Create a new VectorDB from all splits\n",
    "    vectordb = Chroma.from_texts(\n",
    "        texts=all_splits,\n",
    "        embedding=embedding_model.encode,\n",
    "        persist_directory=persist_directory,\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "    print(\"Created new VectorDB and saved to:\", persist_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SentenceTransformer' object has no attribute 'embed_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Create a new VectorDB from text data if not found\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     splits \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExample text 1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExample text 2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# Replace with your actual text data\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     vectordb \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new VectorDB and saved to:\u001b[39m\u001b[38;5;124m\"\u001b[39m, persist_directory)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Initialize the language model\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/vectorstores/chroma.py:843\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    837\u001b[0m         chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(\n\u001b[1;32m    838\u001b[0m             texts\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m [],\n\u001b[1;32m    839\u001b[0m             metadatas\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    840\u001b[0m             ids\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    841\u001b[0m         )\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 843\u001b[0m     \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/vectorstores/chroma.py:277\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m(texts)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SentenceTransformer' object has no attribute 'embed_documents'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yt_dlp\n",
    "import whisper\n",
    "import chromadb\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.llms import OpenAI\n",
    "import gradio as gr\n",
    "import asyncio\n",
    "from pytubefix import YouTube\n",
    "import hashlib\n",
    "\n",
    "# Load OpenAI API key\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Whisper model initialization for transcription\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "# ChromaDB initialization for vector storage\n",
    "chroma_client = chromadb.Client()\n",
    "try:\n",
    "    chroma_collection = chroma_client.create_collection(name=\"jackson_galaxy_videos\")\n",
    "except chromadb.errors.UniqueConstraintError:\n",
    "    chroma_collection = chroma_client.get_collection(name=\"jackson_galaxy_videos\")\n",
    "\n",
    "# Define the directory for downloaded audio files\n",
    "output_path = \"path/to/m4a\"\n",
    "os.makedirs(output_path, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "# List of YouTube URLs\n",
    "video_urls = [\n",
    "    \"https://youtu.be/ZUcVUFvmDFE?si=z9GfOAWF1qothiKs\",\n",
    "    \"https://youtu.be/4DlJYcfiRu4?si=cUVT9L5dEEdkcSt_\",\n",
    "    \"https://youtu.be/rxInrRQLEmM?si=Ai7wHN0dI--cns0x\",\n",
    "    \"https://youtu.be/gxlNfh5ukMw?si=naO3n4VZeXx3PlOs\",\n",
    "    \"https://youtu.be/ojS7XwtoXtw?si=NpNSef7dCm_LnFPv\",\n",
    "    \"https://youtu.be/tsYT7yIOdqQ?si=hdGEpxlmFNMf7NNQ\",\n",
    "    \"https://youtu.be/tsYT7yIOdqQ?si=e_Zdh2dGpqempHR8\",\n",
    "    \"https://youtu.be/UWohxDOXsl4?si=y1nXlUZYw6uzkc8n\",\n",
    "    \"https://youtu.be/gZrwcoiy_gY?si=ksfYE03t6xtuxUL0\",\n",
    "    \"https://youtu.be/lSDI5diNu4Y?si=Q-In6zMD4ZpuaPIz\",\n",
    "    \"https://youtu.be/8aCGL9GpVUg?si=_0yF1U1thjwJqyPY\",\n",
    "    \"https://youtu.be/VjOXvD7OvrE?si=t6xugNxLeMjpsi7E\",\n",
    "    \"https://youtu.be/FzifwTnCV5s?si=sR_u4kG-4NoQx5Ux\",\n",
    "    \"https://youtu.be/XreeFU7RYeI?si=hsc9WO24dJP6AfV2\",\n",
    "    \"https://youtu.be/-4O97jw_8Bc?si=pC14dgZ_f4mXdYPv\"\n",
    "]\n",
    "\n",
    "# Function to create a unique filename from URL\n",
    "def generate_filename(url, extension=\"m4a\"):\n",
    "    \"\"\"Creates a unique filename for each URL based on its hash.\"\"\"\n",
    "    return hashlib.md5(url.encode()).hexdigest() + f\".{extension}\"\n",
    "\n",
    "# Download each video as audio and handle errors\n",
    "failed_downloads = []  # To log any failed downloads\n",
    "\n",
    "for url in video_urls:\n",
    "    # Generate filename and check if it exists\n",
    "    filename = generate_filename(url)\n",
    "    file_path = os.path.join(output_path, filename)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Already downloaded: {url}\")\n",
    "        continue  # Skip downloading if file exists\n",
    "    \n",
    "    # Download video if not already downloaded\n",
    "    try:\n",
    "        yt = YouTube(url)\n",
    "        video = yt.streams.filter(only_audio=True).first()\n",
    "        video.download(output_path=output_path, filename=filename)\n",
    "        print(f\"Downloaded: {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n",
    "        failed_downloads.append(url)\n",
    "\n",
    "# Optional: log failed downloads if any\n",
    "if failed_downloads:\n",
    "    print(\"Failed Downloads:\", failed_downloads)\n",
    "    # You could write these to a log file for later review\n",
    "\n",
    "# Step 1: Video Transcription Using Whisper (Updated)\n",
    "def transcribe_video_from_file(audio_path, metadata):\n",
    "    # Transcribe audio\n",
    "    result = whisper_model.transcribe(audio_path)\n",
    "    transcription = result['text']\n",
    "    \n",
    "    # Store transcription in ChromaDB\n",
    "    add_to_chromadb(transcription, metadata)\n",
    "\n",
    "# Step 2: Add Transcription to ChromaDB\n",
    "def add_to_chromadb(transcription, metadata):\n",
    "    embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "    vector = embedding_model.embed_documents([transcription])[0]\n",
    "    chroma_collection.add(documents=[transcription], metadatas=[{\"source\": metadata}], embeddings=[vector])\n",
    "\n",
    "# Transcribe all downloaded audio files and add to ChromaDB\n",
    "for url in video_urls:\n",
    "    filename = generate_filename(url)\n",
    "    file_path = os.path.join(output_path, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        transcribe_video_from_file(file_path, url)\n",
    "\n",
    "# Step 3: Retrieval-Augmented Generation (RAG) Pipeline\n",
    "def generate_response(query):\n",
    "    embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "    vectordb = Chroma(collection=chroma_collection, embedding_function=embedding_model.embed_query)\n",
    "    retriever = vectordb.as_retriever()\n",
    "    qa_chain = RetrievalQA(llm=OpenAI(openai_api_key=OPENAI_API_KEY), retriever=retriever)\n",
    "    return qa_chain.run(query)\n",
    "\n",
    "# Step 4: Using LangChain Agents to Automate Workflow\n",
    "def setup_agents():\n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"Transcribe Video\",\n",
    "            func=transcribe_video_from_file,\n",
    "            description=\"Use this to transcribe an audio file using Whisper\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"Generate Response\",\n",
    "            func=generate_response,\n",
    "            description=\"Use this to generate responses based on transcriptions using RAG\"\n",
    "        )\n",
    "    ]\n",
    "    llm = OpenAI(temperature=0.7, openai_api_key=OPENAI_API_KEY)\n",
    "    agent = initialize_agent(tools, llm, agent_type=\"zero-shot-react-description\", verbose=True)\n",
    "    return agent\n",
    "\n",
    "agent = setup_agents()\n",
    "\n",
    "# Gradio Interface for User Interaction\n",
    "def ask_question_gradio(question):\n",
    "    response = asyncio.run(asyncio.to_thread(agent.run, f\"Generate Response: {question}\"))\n",
    "    return response\n",
    "\n",
    "iface = gr.Interface(fn=ask_question_gradio, inputs=\"text\", outputs=\"text\", title=\"Jackson Galaxy Chatbot\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Launch Gradio interface\n",
    "    iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
