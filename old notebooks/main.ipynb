{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat Chat Bot Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation command\n",
    "%pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pytube\n",
    "%pip install --upgrade pytube\n",
    "%pip install yt-dlp\n",
    "%pip install moviepy\n",
    "%pip install whisper\n",
    "%pip install chromadb sentence-transformers\n",
    "%pip install git+https://github.com/openai/whisper.git\n",
    "%pip install pytubefix\n",
    "%pip install chromadb\n",
    "%pip install langchain\n",
    "%pip install openai\n",
    "%pip install opencv-python\n",
    "%pip install langchain_openai\n",
    "%pip install --upgrade huggingface_hub\n",
    "%pip install --upgrade sentence-transformers\n",
    "%pip install langchain_community\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import langsmith\n",
    "\n",
    "# Specify the path to the .env file\n",
    "dotenv_path = \"./notebooks/apikey.env\" #Change if your env is in a diffretn folder\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Ensure required environment variables are loaded\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "# Check if all environment variables are set; raise an error if any are missing\n",
    "if not all([OPENAI_API_KEY, LANGCHAIN_API_KEY, HUGGINGFACEHUB_API_TOKEN]):\n",
    "    raise ValueError(\"Some required API keys are missing in the .env file.\")\n",
    "\n",
    "# Enable LangSmith tracing with environment variables\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"cat_expert_knowledge\"\n",
    "\n",
    "# Initialize LangSmith Client\n",
    "from langsmith import Client\n",
    "client = Client(api_key=LANGCHAIN_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/notebooks'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
  
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the videos to learn.\n",
    "Video to Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded: https://youtu.be/ZUcVUFvmDFE?si=z9GfOAWF1qothiKs\n",
      "Already downloaded: https://youtu.be/4DlJYcfiRu4?si=cUVT9L5dEEdkcSt_\n",
      "Already downloaded: https://youtu.be/rxInrRQLEmM?si=Ai7wHN0dI--cns0x\n",
      "Already downloaded: https://youtu.be/gxlNfh5ukMw?si=naO3n4VZeXx3PlOs\n",
      "Already downloaded: https://youtu.be/ojS7XwtoXtw?si=NpNSef7dCm_LnFPv\n",
      "Already downloaded: https://youtu.be/tsYT7yIOdqQ?si=hdGEpxlmFNMf7NNQ\n",
      "Already downloaded: https://youtu.be/tsYT7yIOdqQ?si=e_Zdh2dGpqempHR8\n",
      "Already downloaded: https://youtu.be/UWohxDOXsl4?si=y1nXlUZYw6uzkc8n\n",
      "Already downloaded: https://youtu.be/gZrwcoiy_gY?si=ksfYE03t6xtuxUL0\n",
      "Already downloaded: https://youtu.be/lSDI5diNu4Y?si=Q-In6zMD4ZpuaPIz\n",
      "Already downloaded: https://youtu.be/8aCGL9GpVUg?si=_0yF1U1thjwJqyPY\n",
      "Already downloaded: https://youtu.be/VjOXvD7OvrE?si=t6xugNxLeMjpsi7E\n",
      "Already downloaded: https://youtu.be/FzifwTnCV5s?si=sR_u4kG-4NoQx5Ux\n",
      "Already downloaded: https://youtu.be/XreeFU7RYeI?si=hsc9WO24dJP6AfV2\n",
      "Already downloaded: https://youtu.be/-4O97jw_8Bc?si=pC14dgZ_f4mXdYPv\n"
     ]
    }
   ],
   "source": [
    "from pytubefix import YouTube\n",
    "import os\n",
    "import hashlib\n",
    "\n",
    "# Define the directory for downloaded audio files\n",
    "output_path = \"path/to/m4a\"\n",
    "os.makedirs(output_path, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "# Replace with your list of YouTube URLs\n",
    "video_urls = [\"https://youtu.be/ZUcVUFvmDFE?si=z9GfOAWF1qothiKs\", \n",
    "            \"https://youtu.be/4DlJYcfiRu4?si=cUVT9L5dEEdkcSt_\", \n",
    "            \"https://youtu.be/rxInrRQLEmM?si=Ai7wHN0dI--cns0x\", \n",
    "            \"https://youtu.be/gxlNfh5ukMw?si=naO3n4VZeXx3PlOs\", \n",
    "            \"https://youtu.be/ojS7XwtoXtw?si=NpNSef7dCm_LnFPv\", \n",
    "            \"https://youtu.be/tsYT7yIOdqQ?si=hdGEpxlmFNMf7NNQ\", \n",
    "            \"https://youtu.be/tsYT7yIOdqQ?si=e_Zdh2dGpqempHR8\", \n",
    "            \"https://youtu.be/UWohxDOXsl4?si=y1nXlUZYw6uzkc8n\", \n",
    "            \"https://youtu.be/gZrwcoiy_gY?si=ksfYE03t6xtuxUL0\", \n",
    "            \"https://youtu.be/lSDI5diNu4Y?si=Q-In6zMD4ZpuaPIz\", \n",
    "            \"https://youtu.be/8aCGL9GpVUg?si=_0yF1U1thjwJqyPY\", \n",
    "            \"https://youtu.be/VjOXvD7OvrE?si=t6xugNxLeMjpsi7E\", \n",
    "            \"https://youtu.be/FzifwTnCV5s?si=sR_u4kG-4NoQx5Ux\", \n",
    "            \"https://youtu.be/XreeFU7RYeI?si=hsc9WO24dJP6AfV2\", \n",
    "            \"https://youtu.be/-4O97jw_8Bc?si=pC14dgZ_f4mXdYPv\" ]\n",
    "\n",
    "# Function to create a unique filename from URL\n",
    "def generate_filename(url, extension=\"m4a\"):\n",
    "    \"\"\"Creates a unique filename for each URL based on its hash.\"\"\"\n",
    "    return hashlib.md5(url.encode()).hexdigest() + f\".{extension}\"\n",
    "\n",
    "# Download each video as audio and handle errors\n",
    "failed_downloads = []  # To log any failed downloads\n",
    "\n",
    "for url in video_urls:\n",
    "    # Generate filename and check if it exists\n",
    "    filename = generate_filename(url)\n",
    "    file_path = os.path.join(output_path, filename)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Already downloaded: {url}\")\n",
    "        continue  # Skip downloading if file exists\n",
    "    \n",
    "    # Download video if not already downloaded\n",
    "    try:\n",
    "        yt = YouTube(url)\n",
    "        video = yt.streams.filter(only_audio=True).first()\n",
    "        video.download(output_path=output_path, filename=filename)\n",
    "        print(f\"Downloaded: {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n",
    "        failed_downloads.append(url)\n",
    "\n",
    "# Optional: log failed downloads if any\n",
    "if failed_downloads:\n",
    "    print(\"Failed Downloads:\", failed_downloads)\n",
    "    # You could write these to a log file for later review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcriptions done by Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribed and saved: /notebooks/path/to/transcriptions/c4181c7e744aaaae5aaf7e234e39a17e.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/c813c650315977e7da699c0b2d52799d.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/When Cat Introductions Get UGLY.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/6e43a9a97ff958b094ee86b59d6fa433.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/Can my Cats Get Along? Cat-to-Cat Body Language basics & Introduction Tips.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/How To Introduce Your Cat to a New KITTEN!.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/How to Introduce Cats.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/Are My Cats Playing or Fighting? | Cat Playing vs Cat Aggression.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/Cat Introductions Gone Wrong: They Will NOT Work it Out Without You.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/55340c0bd9e5d16b88d7bdc38908eccc.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/14744c59f76c5a6fb10402ccdd3e280e.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/4c4c7f472299b10d74dee0ecdc941b3b.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/This was BAD!! üôÄü§Øü´£ #shorts.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/f72adde394a4d4b403421fd7bb5324fb.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/The Do's & Don'ts of Introducing Cats.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/0ad0281d64cf5d1e366881ec6adfbd9f.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/b81b63d4601ef135d3641d91fa8e5920.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/Cat Introductions: Good First Impressions are a must!.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/The Best Way To Introduce Your Two Cats.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/Cat Introductions: Does your Senior Need A Friend?.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/89438d05ab80fbaad4194f97dcf8f786.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/de747e570a36df03149fca7596d7686e.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/Why You Should Get Another Cat.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/Can Cats & Dogs Be Friends? | Jackson Galaxy.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/fa8c74567ee31f6e4bdfc0abb681f0a4.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/55f9f04d946d68dcac4bff1b1292a8c5.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/Brady Bunching: Introducing Two Groups of Cats.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/f6d781840478116e21403e46776c5d21.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/23e9e0c657974c427119ed6e734c704d.txt\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Directory containing your .m4a files\n",
    "audio_dir = \"/notebooks/path/to/m4a\"\n",
    "transcription_dir = \"/notebooks/path/to/transcriptions\"\n",
    "\n",
    "# Ensure the transcription directory exists\n",
    "os.makedirs(transcription_dir, exist_ok=True)\n",
    "\n",
    "# List all .m4a files in the audio directory\n",
    "audio_files = [f for f in os.listdir(audio_dir) if f.endswith(\".m4a\")]\n",
    "\n",
    "# Transcribe each audio file and save it as a .txt file\n",
    "for audio_file in audio_files:\n",
    "    audio_path = os.path.join(audio_dir, audio_file)\n",
    "    try:\n",
    "        transcription = model.transcribe(audio_path)\n",
    "\n",
    "        # Save transcription to a .txt file\n",
    "        \n",
    "        transcription_file = os.path.join(transcription_dir, audio_file.replace(\".m4a\", \".txt\"))\n",
    "        with open(transcription_file, \"w\") as f:\n",
    "            f.write(transcription['text'])\n",
    "        print(f\"Transcribed and saved: {transcription_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to transcribe {audio_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if the transcriptions are on the right path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found transcription files: [\"path/to/transcriptions/The Do's & Don'ts of Introducing Cats.txt\", 'path/to/transcriptions/c813c650315977e7da699c0b2d52799d.txt', 'path/to/transcriptions/55340c0bd9e5d16b88d7bdc38908eccc.txt', 'path/to/transcriptions/Can my Cats Get Along? Cat-to-Cat Body Language basics & Introduction Tips.txt', 'path/to/transcriptions/When Cat Introductions Get UGLY.txt', 'path/to/transcriptions/c4181c7e744aaaae5aaf7e234e39a17e.txt', 'path/to/transcriptions/fa8c74567ee31f6e4bdfc0abb681f0a4.txt', 'path/to/transcriptions/Brady Bunching: Introducing Two Groups of Cats.txt', 'path/to/transcriptions/Can Cats & Dogs Be Friends? | Jackson Galaxy.txt', 'path/to/transcriptions/b81b63d4601ef135d3641d91fa8e5920.txt', 'path/to/transcriptions/6e43a9a97ff958b094ee86b59d6fa433.txt', 'path/to/transcriptions/Cat Introductions: Good First Impressions are a must!.txt', 'path/to/transcriptions/How to Introduce Cats.txt', 'path/to/transcriptions/This was BAD!! üôÄü§Øü´£ #shorts.txt', 'path/to/transcriptions/f6d781840478116e21403e46776c5d21.txt', 'path/to/transcriptions/14744c59f76c5a6fb10402ccdd3e280e.txt', 'path/to/transcriptions/89438d05ab80fbaad4194f97dcf8f786.txt', 'path/to/transcriptions/0ad0281d64cf5d1e366881ec6adfbd9f.txt', 'path/to/transcriptions/The Best Way To Introduce Your Two Cats.txt', 'path/to/transcriptions/Cat Introductions: Does your Senior Need A Friend?.txt', 'path/to/transcriptions/23e9e0c657974c427119ed6e734c704d.txt', 'path/to/transcriptions/de747e570a36df03149fca7596d7686e.txt', 'path/to/transcriptions/4c4c7f472299b10d74dee0ecdc941b3b.txt', 'path/to/transcriptions/f72adde394a4d4b403421fd7bb5324fb.txt', 'path/to/transcriptions/Why You Should Get Another Cat.txt', 'path/to/transcriptions/How To Introduce Your Cat to a New KITTEN!.txt', 'path/to/transcriptions/55f9f04d946d68dcac4bff1b1292a8c5.txt', 'path/to/transcriptions/Are My Cats Playing or Fighting? | Cat Playing vs Cat Aggression.txt', 'path/to/transcriptions/Cat Introductions Gone Wrong: They Will NOT Work it Out Without You.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the directory for transcription files\n",
    "transcription_dir = \"path/to/transcriptions\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(transcription_dir):\n",
    "    print(f\"The transcription directory {transcription_dir} does not exist.\")\n",
    "else:\n",
    "    # List transcription files\n",
    "    transcription_files = glob.glob(os.path.join(transcription_dir, \"*.txt\"))\n",
    "    if not transcription_files:\n",
    "        print(f\"No .txt transcription files found in {transcription_dir}.\")\n",
    "    else:\n",
    "        print(f\"Found transcription files: {transcription_files}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chromadb as Client and creation of Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing collection: cat_expert_knowledge\n",
      "Document with ID b64775dda1d19800faf705fc285d0b39 already exists in ChromaDB. Skipping.\n",
      "Document with ID b64775dda1d19800faf705fc285d0b39 already exists in ChromaDB. Skipping.\n",
      "Document with ID fd4d02a8b57e29119b6790372d447c5c already exists in ChromaDB. Skipping.\n",
      "Document with ID 8feb133471c4ccb7c3ef7250d40c6df2 already exists in ChromaDB. Skipping.\n",
      "Document with ID a4e4e5695490b334f78225d4e100e0b2 already exists in ChromaDB. Skipping.\n",
      "Document with ID b472d1bcb7e3082fc1e88755987ab76a already exists in ChromaDB. Skipping.\n",
      "Document with ID 099c99dd958dcdb0b42bf7a042932590 already exists in ChromaDB. Skipping.\n",
      "Document with ID 68c751d8986d924ff7bbb9325eebec7c already exists in ChromaDB. Skipping.\n",
      "Document with ID a015dbd299e90f7bf1f232372463a392 already exists in ChromaDB. Skipping.\n",
      "Document with ID fd4d02a8b57e29119b6790372d447c5c already exists in ChromaDB. Skipping.\n",
      "Document with ID 5535ae3ef6377118f115b87cf8582ab2 already exists in ChromaDB. Skipping.\n",
      "Document with ID ab240479c60573cc892d3bea54a3a8f8 already exists in ChromaDB. Skipping.\n",
      "Document with ID fd4d02a8b57e29119b6790372d447c5c already exists in ChromaDB. Skipping.\n",
      "Document with ID 299089fe015d28b760822c8cbf8e2c44 already exists in ChromaDB. Skipping.\n",
      "Document with ID 8c072b2935ba56ef6a1019f448058527 already exists in ChromaDB. Skipping.\n",
      "Document with ID 2e82731fe037f0c553f2955f10997021 already exists in ChromaDB. Skipping.\n",
      "Document with ID a015dbd299e90f7bf1f232372463a392 already exists in ChromaDB. Skipping.\n",
      "Document with ID 299089fe015d28b760822c8cbf8e2c44 already exists in ChromaDB. Skipping.\n",
      "Document with ID b472d1bcb7e3082fc1e88755987ab76a already exists in ChromaDB. Skipping.\n",
      "Document with ID ea8717cbb557a0191247d346c71e800b already exists in ChromaDB. Skipping.\n",
      "Document with ID ab240479c60573cc892d3bea54a3a8f8 already exists in ChromaDB. Skipping.\n",
      "Document with ID 68c751d8986d924ff7bbb9325eebec7c already exists in ChromaDB. Skipping.\n",
      "Document with ID b706543798cf8e072016fba436ff4b23 already exists in ChromaDB. Skipping.\n",
      "Document with ID ea8717cbb557a0191247d346c71e800b already exists in ChromaDB. Skipping.\n",
      "Document with ID b706543798cf8e072016fba436ff4b23 already exists in ChromaDB. Skipping.\n",
      "Document with ID 5535ae3ef6377118f115b87cf8582ab2 already exists in ChromaDB. Skipping.\n",
      "Document with ID 849526dd365786e365f5cc86ac5084f0 already exists in ChromaDB. Skipping.\n",
      "Document with ID 2e82731fe037f0c553f2955f10997021 already exists in ChromaDB. Skipping.\n",
      "Document with ID 099c99dd958dcdb0b42bf7a042932590 already exists in ChromaDB. Skipping.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import glob\n",
    "import hashlib\n",
    "\n",
    "# Initialize ChromaDB client and set up the collection\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Check if the collection exists; create if not\n",
    "collection_name = \"cat_expert_knowledge\"\n",
    "if collection_name not in [col.name for col in client.list_collections()]:\n",
    "    collection = client.create_collection(collection_name)\n",
    "else:\n",
    "    collection = client.get_collection(collection_name)\n",
    "    print(f\"Using existing collection: {collection_name}\")\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Directory containing transcription files\n",
    "transcription_dir = \"path/to/transcriptions\"\n",
    "\n",
    "def generate_document_id(text):\n",
    "    \"\"\"Generate a unique hash ID for each document based on its text content.\"\"\"\n",
    "    return hashlib.md5(text.encode()).hexdigest()\n",
    "\n",
    "def add_document_to_chromadb(file_path, collection):\n",
    "    \"\"\"Adds a document to ChromaDB if it doesn't already exist.\"\"\"\n",
    "    # Read file content\n",
    "    with open(file_path, \"r\") as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # Generate a unique ID based on document content\n",
    "    doc_id = generate_document_id(text)\n",
    "    \n",
    "    # Query to check if this document hash already exists\n",
    "    existing_docs = collection.query(\n",
    "        query_texts=[doc_id], \n",
    "        where={\"topic\": doc_id}\n",
    "    )\n",
    "    if existing_docs['documents']:  # If results found, skip adding\n",
    "        print(f\"Document with ID {doc_id} already exists in ChromaDB. Skipping.\")\n",
    "        return\n",
    "    \n",
    "    # Embed the text and add to ChromaDB\n",
    "    embedding = embedding_model.encode(text).tolist()\n",
    "    collection.add(\n",
    "        ids=[doc_id],\n",
    "        documents=[text],\n",
    "        metadatas=[{\"topic\": doc_id, \"source\": file_path}],\n",
    "        embeddings=[embedding]\n",
    "    )\n",
    "    print(f\"Document {doc_id} added to ChromaDB.\")\n",
    "\n",
    "# Process each transcription file\n",
    "transcription_files = glob.glob(os.path.join(transcription_dir, \"*.txt\"))\n",
    "if not transcription_files:\n",
    "    print(\"No transcription files found in the specified directory.\")\n",
    "\n",
    "for transcription_file in transcription_files:\n",
    "    try:\n",
    "        add_document_to_chromadb(transcription_file, collection)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to add {transcription_file} to ChromaDB: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# RAG and Results in character with History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response: content=\"Hey there! I totally understand your concern about your cat scratching furniture. It's a pretty common behavior for our feline friends. One tip is to provide plenty of appropriate scratching posts or pads for your cat to use instead of your furniture. You can also try using double-sided tape or a citrus spray on the furniture to deter them from scratching. Remember, positive reinforcement when they use the scratching post can also help reinforce the behavior. Stay patient and consistent, and your cat will hopefully learn to scratch in the right place!\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 104, 'prompt_tokens': 56, 'total_tokens': 160, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-93a661a3-a481-490c-b95a-888540c729c7-0' usage_metadata={'input_tokens': 56, 'output_tokens': 104, 'total_tokens': 160, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import glob\n",
    "import hashlib\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Initialize other components\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "client = chromadb.Client()\n",
    "collection = client.get_collection(\"cat_expert_knowledge\")\n",
    "\n",
    "# Store conversation history as a list of dictionaries\n",
    "conversation_history = []\n",
    "\n",
    "def query_rag_with_history(collection, query_text, embedding_model, llm, conversation_history, n_results=3, max_history_length=5):\n",
    "    \"\"\"\n",
    "    Perform a RAG query and generate a response, while considering conversation history.\n",
    "    \n",
    "    Parameters:\n",
    "    - collection: ChromaDB collection to query.\n",
    "    - query_text: The question or input text for querying.\n",
    "    - embedding_model: Sentence embedding model (e.g., SentenceTransformer).\n",
    "    - llm: Language model from LangChain for generating responses.\n",
    "    - conversation_history: List storing past interactions.\n",
    "    - n_results: Number of relevant documents to retrieve.\n",
    "    - max_history_length: Maximum number of history turns to keep.\n",
    "    \n",
    "    Returns:\n",
    "    - response: Generated answer from the language model based on retrieved documents.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Embed the query text\n",
    "    query_embedding = embedding_model.encode(query_text).tolist()\n",
    "    \n",
    "    # Perform the search in ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    \n",
    "    # Check if documents are found\n",
    "    if results['documents']:\n",
    "        # Prepare the context from retrieved documents\n",
    "        context_texts = [doc for doc in results['documents'][0]]\n",
    "        context = \"\\n\".join(context_texts)\n",
    "\n",
    "        # Build the conversation history text\n",
    "        history_text = \"\"\n",
    "        for turn in conversation_history:\n",
    "            history_text += f\"User: {turn['user']}\\nJackson Galaxy Bot: {turn['bot']}\\n\"\n",
    "\n",
    "        # Formulate the prompt, including conversation history and context\n",
    "        prompt = (\n",
    "            f\"{history_text}\"\n",
    "            f\"Context:\\n{context}\\n\\n\"\n",
    "            f\"You are Jackson Galaxy, a cat behavior expert known for your empathetic and practical advice. \"\n",
    "            f\"Respond as if you are Jackson, offering friendly and engaging guidance.\\n\\n\"\n",
    "            f\"User: {query_text}\\nJackson Galaxy Bot:\"\n",
    "        )\n",
    "\n",
    "        # Generate response using the language model\n",
    "        response = llm.invoke(prompt)\n",
    "\n",
    "        # Update conversation history\n",
    "        conversation_history.append({\"user\": query_text, \"bot\": response})\n",
    "\n",
    "        # Manage the size of the conversation history\n",
    "        if len(conversation_history) > max_history_length:\n",
    "            conversation_history.pop(0)  #Remove the oldest interaction\n",
    "\n",
    "        return response\n",
    "    else:\n",
    "        return \"No relevant documents found for this query.\"\n",
    "\n",
    "# Example Usage\n",
    "query_text = \"How do I stop my cat from scratching furniture?\"\n",
    "response = query_rag_with_history(collection, query_text, embedding_model, llm, conversation_history)\n",
    "print(\"Generated Response:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistance Memory with RAG query and storing the user conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from langchain_openai import ChatOpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "\n",
    "# Initialize the language model and embedding model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "client = chromadb.Client()\n",
    "collection = client.get_collection(\"cat_expert_knowledge\")\n",
    "\n",
    "# Set up SQLite database connection\n",
    "conn = sqlite3.connect(\"conversation_history.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Function to load conversation history from the database\n",
    "def load_from_database():\n",
    "    cursor.execute(\"SELECT user, bot FROM history\")\n",
    "    return cursor.fetchall()\n",
    "\n",
    "# Function to save conversation history to the database\n",
    "def save_to_database(user_text, bot_response):\n",
    "    cursor.execute(\"INSERT INTO history (user, bot) VALUES (?, ?)\", (user_text, bot_response))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag_with_persistence(collection, query_text, embedding_model, llm, max_history_length=5):\n",
    "    \"\"\"\n",
    "    Perform a RAG query, generate a response, and use persistent storage for conversation history.\n",
    "    \"\"\"\n",
    "    # Load conversation history from the database\n",
    "    conversation_history = load_from_database()\n",
    "\n",
    "    # Embed the query text\n",
    "    query_embedding = embedding_model.encode(query_text).tolist()\n",
    "\n",
    "    # Perform the search in ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=3\n",
    "    )\n",
    "\n",
    "    # Check if documents are found\n",
    "    if results['documents']:\n",
    "        # Prepare the context from retrieved documents\n",
    "        context_texts = [doc for doc in results['documents'][0]]\n",
    "        context = \"\\n\".join(context_texts)\n",
    "\n",
    "        # Build the conversation history text\n",
    "        history_text = \"\"\n",
    "        for user, bot in conversation_history:\n",
    "            history_text += f\"User: {user}\\nJackson Galaxy Bot: {bot}\\n\"\n",
    "\n",
    "        # Formulate the prompt, including conversation history and context\n",
    "        prompt = (\n",
    "            f\"{history_text}\"\n",
    "            f\"Context:\\n{context}\\n\\n\"\n",
    "            f\"You are Jackson Galaxy, a cat behavior expert known for your empathetic and practical advice. \"\n",
    "            f\"Respond as if you are Jackson, offering friendly and engaging guidance.\\n\\n\"\n",
    "            f\"User: {query_text}\\nJackson Galaxy Bot:\"\n",
    "        )\n",
    "\n",
    "        # Generate response using the language model\n",
    "        response = llm.invoke(prompt)\n",
    "        \n",
    "        # Convert the response to a string using .content\n",
    "        bot_response_text = response.content\n",
    "\n",
    "        # Save the new interaction to the database\n",
    "        save_to_database(query_text, bot_response_text)\n",
    "\n",
    "        # Manage the size of the conversation history\n",
    "        if len(conversation_history) >= max_history_length:\n",
    "            cursor.execute(\"DELETE FROM history WHERE id = (SELECT MIN(id) FROM history)\")\n",
    "            conn.commit()\n",
    "\n",
    "        return bot_response_text\n",
    "    else:\n",
    "        return \"No relevant documents found for this query.\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out put of the text above ^ ^ ^ ^ ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response: Hey there! Introducing cats to each other can be a delicate process, but with patience and the right approach, you can help them become friends. Start by keeping the new cat in a separate room with all their essentials (food, water, litter box, toys) for a few days to let them get used to their new surroundings. Then, swap bedding or toys between the cats so they can get used to each other's scents. Next, gradually introduce them by using a barrier like a baby gate or cracked door so they can see and smell each other without direct contact. Keep interactions positive and rewarding with treats and playtime. And remember, every cat is unique, so go at their pace and be prepared for some hissing or swatting initially. With time and patience, they can learn to coexist peacefully. Good luck! üò∫üêæ #TeamCatmojo\n"
     ]
    }
   ],
   "source": [
    "# Example Usage with Debugging Prints\n",
    "query_text = \"How do I Introcude my cat to another cat?\"\n",
    "\n",
    "# Call the function and print the result\n",
    "response = query_rag_with_persistence(collection, query_text, embedding_model, llm)\n",
    "\n",
    "# Check if the response was generated and print it\n",
    "if response:\n",
    "    print(\"Generated Response:\", response)\n",
    "else:\n",
    "    print(\"No response generated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* Running on public URL: https://1c004f8a18fe3e4b7e.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://1c004f8a18fe3e4b7e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2015, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1562, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 865, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36/4038534535.py\", line 83, in chat_with_jackson\n",
      "    response = query_rag_with_persistence(collection, query_text, embedding_model, llm)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36/4038534535.py\", line 32, in query_rag_with_persistence\n",
      "    conversation_history = load_from_database()\n",
      "                           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_36/4038534535.py\", line 19, in load_from_database\n",
      "    cursor.execute(\"SELECT user, bot FROM history\")\n",
      "sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 139700001714176 and this is thread id 139688023148096.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from langchain_openai import ChatOpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import gradio as gr\n",
    "\n",
    "# Initialize the language model and embedding model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "client = chromadb.Client()\n",
    "collection = client.get_collection(\"cat_expert_knowledge\")\n",
    "\n",
    "# Set up SQLite database connection\n",
    "conn = sqlite3.connect(\"conversation_history.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Function to load conversation history from the database\n",
    "def load_from_database():\n",
    "    cursor.execute(\"SELECT user, bot FROM history\")\n",
    "    return cursor.fetchall()\n",
    "\n",
    "# Function to save conversation history to the database\n",
    "def save_to_database(user_text, bot_response):\n",
    "    cursor.execute(\"INSERT INTO history (user, bot) VALUES (?, ?)\", (user_text, bot_response))\n",
    "    conn.commit()\n",
    "\n",
    "def query_rag_with_persistence(collection, query_text, embedding_model, llm, max_history_length=5):\n",
    "    \"\"\"\n",
    "    Perform a RAG query, generate a response, and use persistent storage for conversation history.\n",
    "    \"\"\"\n",
    "    # Load conversation history from the database\n",
    "    conversation_history = load_from_database()\n",
    "\n",
    "    # Embed the query text\n",
    "    query_embedding = embedding_model.encode(query_text).tolist()\n",
    "\n",
    "    # Perform the search in ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=3\n",
    "    )\n",
    "\n",
    "    # Check if documents are found\n",
    "    if results['documents']:\n",
    "        # Prepare the context from retrieved documents\n",
    "        context_texts = [doc for doc in results['documents'][0]]\n",
    "        context = \"\\n\".join(context_texts)\n",
    "\n",
    "        # Build the conversation history text\n",
    "        history_text = \"\"\n",
    "        for user, bot in conversation_history:\n",
    "            history_text += f\"User: {user}\\nJackson Galaxy Bot: {bot}\\n\"\n",
    "\n",
    "        # Formulate the prompt, including conversation history and context\n",
    "        prompt = (\n",
    "            f\"{history_text}\"\n",
    "            f\"Context:\\n{context}\\n\\n\"\n",
    "            f\"You are Jackson Galaxy, a cat behavior expert known for your empathetic and practical advice. \"\n",
    "            f\"Respond as if you are Jackson, offering friendly and engaging guidance.\\n\\n\"\n",
    "            f\"User: {query_text}\\nJackson Galaxy Bot:\"\n",
    "        )\n",
    "\n",
    "        # Generate response using the language model\n",
    "        response = llm.invoke(prompt)\n",
    "        \n",
    "        # Convert the response to a string using .content\n",
    "        bot_response_text = response.content\n",
    "\n",
    "        # Save the new interaction to the database\n",
    "        save_to_database(query_text, bot_response_text)\n",
    "\n",
    "        # Manage the size of the conversation history\n",
    "        if len(conversation_history) >= max_history_length:\n",
    "            cursor.execute(\"DELETE FROM history WHERE id = (SELECT MIN(id) FROM history)\")\n",
    "            conn.commit()\n",
    "\n",
    "        return bot_response_text\n",
    "    else:\n",
    "        return \"No relevant documents found for this query.\"\n",
    "\n",
    "# Define the Gradio interface function\n",
    "def chat_with_jackson(query_text):\n",
    "    response = query_rag_with_persistence(collection, query_text, embedding_model, llm)\n",
    "    return response\n",
    "\n",
    "# Create the Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=chat_with_jackson,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Jackson Galaxy Cat Chatbot\",\n",
    "    description=\"Ask your cat behavior questions and get advice as if from Jackson Galaxy!\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio app\n",
    "#interface. launch()\n",
    "# Launch the Gradio app with sharing enabled\n",
    "interface.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
