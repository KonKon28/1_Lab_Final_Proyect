{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Cat Expert Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the nesesary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pytube\n",
    "%pip install --upgrade pytube\n",
    "%pip install yt-dlp\n",
    "%pip install moviepy\n",
    "%pip install whisper\n",
    "%pip install chromadb sentence-transformers\n",
    "%pip install git+https://github.com/openai/whisper.git\n",
    "%pip install pytubefix\n",
    "%pip install chromadb\n",
    "%pip install langchain\n",
    "%pip install openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangSmith - LangChain evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"cat-expert-knowledge\"\n",
    "#Importing Client from Langsmith\n",
    "from langsmith import Client\n",
    "client = Client(api_key=LANGCHAIN_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the videos to learn.\n",
    "Video to Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytubefix import YouTube\n",
    "\n",
    "# Replace with your list of YouTube URLs\n",
    "video_urls = [\"https://youtu.be/ZUcVUFvmDFE?si=z9GfOAWF1qothiKs\", \n",
    "            \"https://youtu.be/4DlJYcfiRu4?si=cUVT9L5dEEdkcSt_\", \n",
    "            \"https://youtu.be/rxInrRQLEmM?si=Ai7wHN0dI--cns0x\", \n",
    "            \"https://youtu.be/gxlNfh5ukMw?si=naO3n4VZeXx3PlOs\", \n",
    "            \"https://youtu.be/ojS7XwtoXtw?si=NpNSef7dCm_LnFPv\", \n",
    "            \"https://youtu.be/tsYT7yIOdqQ?si=hdGEpxlmFNMf7NNQ\", \n",
    "            \"https://youtu.be/tsYT7yIOdqQ?si=e_Zdh2dGpqempHR8\", \n",
    "            \"https://youtu.be/UWohxDOXsl4?si=y1nXlUZYw6uzkc8n\", \n",
    "            \"https://youtu.be/gZrwcoiy_gY?si=ksfYE03t6xtuxUL0\", \n",
    "            \"https://youtu.be/lSDI5diNu4Y?si=Q-In6zMD4ZpuaPIz\", \n",
    "            \"https://youtu.be/8aCGL9GpVUg?si=_0yF1U1thjwJqyPY\", \n",
    "            \"https://youtu.be/VjOXvD7OvrE?si=t6xugNxLeMjpsi7E\", \n",
    "            \"https://youtu.be/FzifwTnCV5s?si=sR_u4kG-4NoQx5Ux\", \n",
    "            \"https://youtu.be/XreeFU7RYeI?si=hsc9WO24dJP6AfV2\", \n",
    "            \"https://youtu.be/-4O97jw_8Bc?si=pC14dgZ_f4mXdYPv\" ]\n",
    "\n",
    "for url in video_urls:\n",
    "    yt = YouTube(url)\n",
    "    video = yt.streams.filter(only_audio=True).first()\n",
    "    video.download(output_path=\"path/to/m4a\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcriptions done by Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribed and saved: /notebooks/path/to/transcriptions/When Cat Introductions Get UGLY.txt\n",
      "Transcribed and saved: /notebooks/path/to/transcriptions/Can my Cats Get Along? Cat-to-Cat Body Language basics & Introduction Tips.txt\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Directory containing your .m4a files\n",
    "audio_dir = \"/notebooks/path/to/m4a/\"\n",
    "transcription_dir = \"/notebooks/path/to/transcriptions/\"\n",
    "\n",
    "# Ensure the transcription directory exists\n",
    "os.makedirs(transcription_dir, exist_ok=True)\n",
    "\n",
    "# List all .m4a files in the audio directory\n",
    "audio_files = [f for f in os.listdir(audio_dir) if f.endswith(\".m4a\")]\n",
    "\n",
    "# Transcribe each audio file and save it as a .txt file\n",
    "for audio_file in audio_files:\n",
    "    audio_path = os.path.join(audio_dir, audio_file)\n",
    "    try:\n",
    "        transcription = model.transcribe(audio_path)\n",
    "\n",
    "        # Save transcription to a .txt file\n",
    "        \n",
    "        transcription_file = os.path.join(transcription_dir, audio_file.replace(\".m4a\", \".txt\"))\n",
    "        with open(transcription_file, \"w\") as f:\n",
    "            f.write(transcription['text'])\n",
    "        print(f\"Transcribed and saved: {transcription_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to transcribe {audio_file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chromadb as Client and creation of Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade huggingface_hub\n",
    "%pip install --upgrade sentence-transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insert of existing embedding ID: doc_0\n",
      "Add of existing embedding ID: doc_0\n",
      "Insert of existing embedding ID: doc_1\n",
      "Add of existing embedding ID: doc_1\n",
      "Insert of existing embedding ID: doc_2\n",
      "Add of existing embedding ID: doc_2\n",
      "Insert of existing embedding ID: doc_3\n",
      "Add of existing embedding ID: doc_3\n",
      "Insert of existing embedding ID: doc_4\n",
      "Add of existing embedding ID: doc_4\n",
      "Insert of existing embedding ID: doc_5\n",
      "Add of existing embedding ID: doc_5\n",
      "Insert of existing embedding ID: doc_6\n",
      "Add of existing embedding ID: doc_6\n",
      "Insert of existing embedding ID: doc_7\n",
      "Add of existing embedding ID: doc_7\n",
      "Insert of existing embedding ID: doc_8\n",
      "Add of existing embedding ID: doc_8\n",
      "Insert of existing embedding ID: doc_9\n",
      "Add of existing embedding ID: doc_9\n",
      "Insert of existing embedding ID: doc_10\n",
      "Add of existing embedding ID: doc_10\n",
      "Insert of existing embedding ID: doc_11\n",
      "Add of existing embedding ID: doc_11\n",
      "Insert of existing embedding ID: doc_12\n",
      "Add of existing embedding ID: doc_12\n",
      "Insert of existing embedding ID: doc_13\n",
      "Add of existing embedding ID: doc_13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcriptions successfully stored in ChromaDB!\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import glob\n",
    "\n",
    "# Initialize ChromaDB client and create a collection\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Check if the collection exists; create if not\n",
    "if \"cat_expert_knowledge\" not in [col.name for col in client.list_collections()]:\n",
    "    collection = client.create_collection(\"cat_expert_knowledge\")\n",
    "else:\n",
    "    collection = client.get_collection(\"cat_expert_knowledge\")\n",
    "\n",
    "\n",
    "# Load the embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Load and process each transcription file\n",
    "for idx, transcription_file in enumerate(glob.glob(\"/notebooks/path/to/transcriptions/*.txt\")):\n",
    "    with open(transcription_file, \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Create an embedding for the transcription\n",
    "    embedding = model.encode(text).tolist()\n",
    "    topic = os.path.basename(transcription_file).replace(\".txt\", \"\")  # Use file name as topic\n",
    "\n",
    "    # Add to ChromaDB collection with a unique ID\n",
    "    collection.add(\n",
    "        ids=[f\"doc_{idx}\"],  # Unique ID for each document\n",
    "        documents=[text],\n",
    "        metadatas=[{\"topic\": topic, \"source\": transcription_file}],\n",
    "        embeddings=[embedding]\n",
    "    )\n",
    "\n",
    "print(\"Transcriptions successfully stored in ChromaDB!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying Chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Text: [\" What's up gang is I Jackson Galaxy your cat daddy and today your cat question answerer that is what I'm here for today hopefully we get questions all the time from folks just like you who sent it into this address right there which you of course can do as well and today we're gonna talk to Kinesha Kinesha what's it all about hi Jackson I'm Kinesha from the Cayman Islands my husband and I have a cat sunshine she's 11 years old and we've always wanted to get another cat to you know keep her company and also rescue from the human society but you know we're a bit worried because she has been the only cat in the home for so long in 11 years and we just wonder whether or not she'll be very receptive to the addition of another cat in the home we'd love your feedback on the best approach to do so you know what can we do to make this a seamless process because we'd really love for it to be a success and to avoid any elimination or scratching or you know any of the behaviors that are likely to be exhibited if she is unhappy with the addition of the new cat which she has done in the past in some instances when you know we have gone out and left her for too long so I'd really love to hear your thoughts on that thank you all right well first of all Kinesha right on I'm so glad that you're all about rescuing the cats in your area who need homes I mean that goes without saying and of course I want you to do that at the same time we do have to take care of what sunshine's needs are at this point and at 11 years old and from what I understand from what you said she's never been around another cat before you know that's that's something you really just need to consider a couple of things that I noticed in what you sent me was first of all this so clearly sunshine is still playful she likes to be a little mischievous and chase things under the sheets and whatnot and that tells us okay so she still has that get up and go at 11 years old is still let's just be very clear about this where she's technically a senior some cats are just more senior than others and some just retain that playfulness that inquisitiveness and it's important to know who sunshine is before we compliment her with someone that sunshine would like now there are a couple of different ways you can go you can adopt another senior and that believe me not just you Kinesha but everyone you guys seniors need homes so much quicker than other cats because the stress that they go through in rescue environments is multiplied because we know that as cats get older they manifest stress physically a lot quicker than younger cats so yeah man getting seniors out of out of rescue situations is paramount so I would definitely encourage that what I would encourage is a cat that maybe has been around other cats before so the adjustment for the newcomer isn't as bad as it could be and by that cat being somewhat relaxed perhaps sunshine will be as well the second way you can go now folks do this all the time they have older cats they are missing the concept of youthful energy and they go out and they adopt a kitten and they always say the same thing it's for the cat my cat needs a friend and let me tell you something your senior cat does not need a kitten no they do not need a kitten in their life they've got this they're settled they have their territory sort of buttoned down they know what every day is going to bring and all of a sudden Dennis the men is shows up with a slingshot and everything is just shot if you are thinking about bringing a kitten into a home with a cat like sunshine first of all remember something whether it's you Kanisha or anybody else it's for you it's not for sunshine sunshine could get used to it but it's because you want another cat in the house and Kanisha made that clear that this is more about what you guys would like so I like the fact that you're starting from there but I'm telling you this you guys if you're going to adopt a younger cat whether it's a kitten or a teenager anywhere in the first year of life adopt to just bring home to to is always better than one especially when it comes to kittens those guys will entertain each other they will learn the ropes they will play at their speed and sunshine then has that ability to watch them from a distance and figure out what this thing is all about and be able to join when she wants to and walk away when she wants to as well yeah every now and again the kittens will decide that sunshine's tail is the best toy in the whole wide world but you guys can deal with that as long as you let sunshine know that this is her place so she doesn't feel like she needs to claim it away from someone else then that's a great place to start so whether it's two kittens or one senior or anywhere in between I guess it's more about when you meet that cat how do you think they'll match up are you getting a cat who is just really really hyper and sunshine doesn't seem to be or are you getting someone who matches her energy level I think that that's really one of the the best things that you can do now whether again it's a kitten or a teenager or a senior or anywhere in between any cat that you go I think sunshine will be able to cope with this cat then it all comes down to the introduction process and and that to me is the most key element of making a resident cat happy who's not been around other cats her whole life just safe introductions if you check out my book Total Cat Mojo you'll see the entire introduction process laid out in exhaustive detail we've got videos about introducing cats so take a look at my videos there's a few I'll leave them in the description one you want to make sure that you establish a really good base camp for your newcomer so that's one video the second one would be about introducing cats don't skip the steps even if you go quickly through them because sunshine is like yeah none of this matters to me great but you might see that it does matter to her that she smells cats under the door and goes what's going on here and as long as you do it slowly and you don't threaten her well-being you know what you can bring cats into the house it's my belief that cats should be with other cats so whether you bring in a senior kinesha whether you bring in a couple of kittens not one but a couple of kittens there's a really good chance that you can make it work to your satisfaction and to sunshine satisfaction right sunshine right all right you guys keep those questions coming all you got to do is go to this link right down here and it will prompt you to basically do exactly what kinesha did so brilliantly which is to say your name your cat's name what your question is and then some footage of your cat doing anything in this case with sunshine just you know enjoying the Cayman Islands which I think any of us would do and this week's team cat Mojo Rockstar is Batman and now obviously the name Batman got me in the first place but Batman is just an expert fetcher let's take a look his person Lisa knows exactly how to toss it Batman knows exactly how to bring it back and everyone's happy except for this innocent bystander right here there's always the cat in the room was like you guys playing fetch again well I don't understand it this is so boring you throw you bring it back you throw you bring it back and I just have to sit here and watch it all day man anyway Batman's Rockstar and your other cat is great just because they provide such brilliant commentary again for your questions you go to Jackson Galaxy dot com forward slash submit for rock stars you do the exact same thing just make sure you're saying hey my cat's a rock star as opposed to hey I've got a question and then everything falls into place from there all right you guys stay safe out there show some love it doesn't take much and and it makes you feel better and it makes the world go around don't it all right light love and Mojo to you guys take care now\", \" Oh my god. I said, why don't we shoot it to the screen right now? Oh my god. Okay, so the first thing is, why did you let it happen? You know, if you see your cat staring down like that, that is a bad thing. That's like two cats holding guns staring at each other and telling the other one to drop a gun. It's 50-50 that they're going to walk away or they're not going to walk away. In those moments of freeze, stop it. Put something in between them. Make sure it doesn't start. And then if you know these two cats are fighting, separate them because there's no good that comes out. That was like six cats in there. So there's a lot of stuff that you can do to prevent fights from happening. And I've got plenty of videos on that. But in the meantime, if these cats keep fighting, keep them separated. Don't let it get to this point. And then we can try to reintroduce them. But boy, that was bad.\", \" What's up, Groovy Cat people, Jackson Galaxy? You're Cat Daddy and I feel like singing about cat introductions. I got a whole iPad full of people asking me questions about cat introductions. So that's what we're going to talk about today. The most asked question that I get is about I'm trying to introduce these cats and something's not going right. Let's meet our unfortunate cat introduction contestants today. First, we have Haley with her cats Ash and Megan. We have got Ivy with her cats May and August. And finally, we have Jay with her cats Feisty and Sparkle. So let's take a look at what these guys have to say. And let's see if you can identify the common problems that keep resurfacing in these households. Let's see how good your cat knowledge is. What kind of a cat Mojo tier are you anyway? Let's find out. Alright, Haley, take it away. I'm currently reaching out because I'm having an issue with my current cat and my new kitten I just adopted. Her name's Megan. My current cat's name is Ash and he's a male. He's about a year old. The issue I'm having is that I followed all the cat introduction videos to a tee. Ash tends to be overly dominant with her. And I don't know how to get it to stop because I've tried distracting him with toys. I've tried distracting both them with toys. I've tried feeding them treats while they're together. But the only thing he's focused on is her. Hopefully you can kind of see what I'm when I'm trying to explain. I tried almost everything I can think of and nothing's working. You've tried everything and it's been a week. Clearly you may have read something but you missed something also. When she turns her head he pounces and he pins her down and sometimes he'll bite her. Like I don't know if it's play biting. I'm pretty sure it's not hard biting because I don't see any scratches. I don't see any blood being drawn. She doesn't get very scared and she'll hiss and grow. But here's your hint. Body language. Okay enough said. Zip it. Megan's like I'm just going to play with my tail. Enough said. Let's move on to Ivy with her cat's May and August. My name is Ivy and I have a question about two cats who's doing introduction for about a month now. May? She's a girl and she's about one year and three month old. And the other cat who's in the another room right now. His name is August and he's a five month old boy. I was doing step by step introduction and it was progressing for like three weeks. And I finally took the fence away and they were doing good for a while. I mean 10-20 minutes. Props Ivy because look we got 10 or 20 minutes and you got there. You can go anywhere. Nice going Ivy. Nice going May and August you know I know it's hard. Yeah it's been a week since that day but it's not progressing at all right now. Sometimes I do put August on the leash and she seems to be doing okay with the leash on. And May seems a little bit more secure. May is clearly quaking in her boots right here. I don't know. I don't know what state they're in right now. I'm not sure if they're going to progress any further. I really need your advice right now. Thank you. Once again not going to give it away. Body language. And that is May playing the part of a squeaky door. And here's that moment. That moment. And finally we have Jay with her cats feisty and sparkle. I have two cats. This one right here is feisty. She is one years old. And this one right here is sparkle. She's the resident cat. She is seven years old. I got feisty the little one. A few months ago in April when my aunt passed away. She was my aunt's cat. And I haven't properly introduced to cats because I have them. I live in a very small apartment. There's only one bedroom. Only one bedroom? With one bedroom you can have 12 cats. Totally kidding people. Totally kidding. Because the younger one feisty, she tends to text sparkle. She will bang on the litter box whenever sparkles and is using it. She will pounce on sparkle like she's a mouse. She will hunt her down. She will chase her around the house. And sparkle would just run under the bed. And feisty will keep doing that multiple times a day. Just keep harassing the older resident cat. And I don't really know what to do. I feel like the place is too small to try to do a proper introduction. Your house is too small to do a proper introduction. I don't think you live in a shipping container day. I think you can capture the great moment here. I mean like a great moment of chaos. But it's great for someone like me who likes to like dissect these things. So take a look at feisty's body language. You know what's going to come next because you guys are not cat rookies. Here we go. Here we go. Ready? Here we go. And boom. Okay. And there goes a sparkle flash. Come on sparkle. All right. Now we've seen our three households, our three contestants. Have you guys figured out what some of the unifying elements are in these three stories? Here's the first commonality out of the three of them. Is that in one way or another, these guys all said, I've done the introduction technique. And I've taken a step by step. But have you really? So let's take a look at Megan and Ash. If you take a look at this and I'm sorry, Hayley. But if you said you did everything according to the book and you went step by step. And this whole thing just took a week. And at a week later, you're like, I don't know what to do. Then maybe reread that section about it because it's supposed to happen slowly. And as we've seen with all three of these, you let them add each other a little bit too fast because in all three of these circumstances, you're just seeing cats wear it. It's like the training wheels got taken off a little fast. When it comes to the step by step introduction technique, you don't move on to the next step until you get like, you know, your little gold star on this step. In all three of these stories, yeah, somehow, like I said, the training wheels came off a little bit too early and then we've got cats going, you know, in the street. It's clear as much as these three humans love their six cats, they're reading them wrong. It's clear that we're using words like here's Hayley saying, Ash tends to be overly dominant with her. Or whether it's Ivy saying this, May actually started hissing to him. We're not figuring out who these cats are. So let's take a look at some good examples of body language that says, I don't consider you to be the enemy. Hey! All right, so here, you've got Megan trying to learn how to speak cat. The thing about Megan, she looks really tiny and that tells me that she probably wasn't around her mom and her siblings long enough. So now she's with a cat and she's trying to figure out what's going on. Now, on the other hand, you've got Ash, who may not have been around other cats before. In fact, my guess is that he wasn't. So now he's trying to do what he did with his brothers and sisters when he was growing up. And that's just way too much for Megan. So that, and how do I know this? Because right here, they're just adjusting their bodies. So you have Ash just laying back. He's kind of like, all right, I really want to play. That's what I'm seeing here. So we see that body language between these two. And we even see at one point right here, you see Megan going and just sort of playing with her own tail at that point. And just trying to figure out if all is good here. So these are the beginnings of dialogue. Now let's go to Ivy and May and August. So we have all kinds of fun little body language ticks here. First, we have the two of them laying there. And don't forget that Ivy said that August is usually the one who's antagonizing. That's, of course, August is wearing his harness. Well, in this shot right here, August has no care about what May is doing. May is sitting right behind him. And August is just like, he even does a little slow blink at one point at Ivy. His focus is on Ivy, not on May. And that's a really good sign. And so that tells me things aren't that bad right here. All right, so we've got body language. And again, in the case of a feisty and sparkle, if we're learning how to talk cat to each other, clearly feisty is not going to listen. But feisty is also a teenager. And, you know, we have to just remember that. That one we need to do something about. So Jay, we'll get back to you in a second. So the third commonality between all three cases here is now it's where we get down to like, hey, human, you got a job here. The one thing that is the override and commonality between these three is that the humans aren't doing anything. The thing is, if you let these two stranger cats, and they're still pretty much strangers because they are getting to know each other, getting to know their body language, is how they work, how they talk, et cetera, how they play, how they fight, you know, what are warnings are, what they're not, et cetera. The human still has to be the source of not just reassurance and not just, hey, cut that out, but also leading around. Don't ever let them get to the point where they're into the stare down. Perfect example here is May and August. Really both cats, but especially May, is sitting here going, I don't know what to do. I don't know what to do. So if we do things that we both know how to do, i.e. play and eat and cuddle and do whatever, anything that involves the human calling the shots, you have a much greater chance of success than just allowing them to keep going and hoping it turns out well, because I can tell you that once the stare down happens, it's less than 50-50. I think it would be 70-30 that it's going to end up badly, especially when they don't know each other. You have the ability in that moment to bring out a toy and lead them away, or bring out two toys and lead them away. But all three of you guys are pretty close, but you got to pay attention to the fact that you have a role here. It's not just setting up the space in between the doors. It's not just when do I open the doors, but you got to have a game plan when the doors open. Once they are able to execute common actions together near one another, that's the best icebreaker in the world, man. It really is. It's like, you know, two people sitting next to each other on a first date. You're on a blind date, and you're sitting there, and you're starting to, like your palms are starting to sweat because you're running out of things to talk about. And then you both realize, wait a minute, you've been to Iceland before, don't you love Iceland? Oh my god, it's the best place in the whole world. Did you go to blah, blah, blah, blah? Did you sit in the hot springs? Yes, wasn't it amazing? You see, and all of a sudden, there we are. I can sort of trust you because you have the same experience that I have. Another not commonality, but individual thing. Let's go to Jay and Feisty and Sparkle. So Jay, you know, one of the things we got to deal with here is, yes, Feisty has a pretty strong prey drive, but he's also a teenager. But one thing is, let's go back to the litter box right here. It's get that litter box out of that corner. Seems like it's got a really high area, like a high lip. Go for a litter box that is just low-sided, no lid. This is why I hate lids on litter boxes, you guys, especially, in multi-cat households, because ambush means that after a while, Sparkle will stop using the litter box. She will stop using it because it's not a safe place. So that's one big thing I would give to you, Jay. We got a work on Feisty, and that leads me to my final thing with all three of you. This is the big one with all three of you guys. Whether we're talking about Ash, August, Feisty, all three of these guys, you really need to play with your cats. Like, you really need to. You got to wear those guys out. We got to bring them down so they're not just full of that cat's static, and they're like, I just got to get this energy out of my system. We just got to get that out of them. So we're talking about separate play times. Don't play with your cats together in these circumstances. Separate them out and exhaust these cats. Take a look at this video over my head right here about the concept I call boil and simmer. Boil and simmer is what you got to do with your high energy, more whatever words you want to use. Dominant, aggressor, bully, fun-loving, teenager, knucklehead, whatever you want to call them. You got to take those that energy down. Now, I could go all day, and I feel like to a certain degree I have, but let's just rewind the commonalities here that we're introducing too fast. We're not hitting that gold star before we go on to the next place. Not really understanding cat body language, and how these guys learn how to relationship. The next thing is that you as the human need to be leading the parade. Don't let the cats call the shots when they're just meeting one another. And then, of course, we have the fact that these aggressor cats or the higher energy cats need to be brought down. So that energy wise, both cats can meet. Oh, and by the way, Jay, you've got a lovely house. It's not too small. As long as you've got a wall, and as long as you've got a door, you can make this happen just fine. Go back and read Total Cat Mojo that chapter about introductions. Read it again and know that you can do this. All for you guys, you can do this. You got a door. You got two different rooms. You've got food. Yay! We can make this work. That's it, you guys. And even if it is about your cats having introduction problems, I don't want you to stop sending in your videos. Just send it right here. Do exactly what these guys did. Even if you're shy like Ivy, and you don't want to show your face. As long as you show your cats plenty, there's a good chance of getting them. And don't forget to subscribe to the channel. That's how we know that we're doing right by you guys. Don't let any of this deter you from not getting another cat in your house. It is a fallacy. It is a stereotype. Cats don't need to be solitary creatures whatsoever. You've just got to do it right. Two is better than one. Three is better than two. In my book, I just, to the bottom of my heart, believe me. So go off and do it. Don't let this video deter you. Okay? Okay. Until next time, you guys all lighten all love and all mojo to your life. Now.\"]\n",
      "Metadata: [{'source': '/notebooks/path/to/transcriptions/Cat Introductions: Does your Senior Need A Friend?.txt', 'topic': 'Cat Introductions: Does your Senior Need A Friend?'}, {'source': '/notebooks/path/to/transcriptions/This was BAD!! ðŸ™€ðŸ¤¯ðŸ«£ #shorts.txt', 'topic': 'This was BAD!! ðŸ™€ðŸ¤¯ðŸ«£ #shorts'}, {'source': '/notebooks/path/to/transcriptions/When Cat Introductions Get UGLY.txt', 'topic': 'When Cat Introductions Get UGLY'}]\n"
     ]
    }
   ],
   "source": [
    "# Sample query to retrieve relevant information\n",
    "query_text = \"How do I stop my cat from scratching furniture?\"\n",
    "query_embedding = model.encode(query_text).tolist()\n",
    "\n",
    "# Perform the search\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "# Check if results are found\n",
    "if results['documents']:\n",
    "    for result in results['documents']:\n",
    "        print(\"Retrieved Text:\", result)\n",
    "    for metadata in results['metadatas']:\n",
    "        print(\"Metadata:\", metadata)\n",
    "else:\n",
    "    print(\"No relevant results found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install langchain\n",
    "#%pip install openai\n",
    "#%pip install langchain_community langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.7'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (24579 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response: content=\"There are several reasons why cats scratch furniture:\\n\\n1. **Territory Marking**: Cats have scent glands in their paws, and scratching is a way for them to mark their territory. By scratching furniture, they are leaving both a visual mark (the scratches) and a scent mark (from the glands in their paws).\\n\\n2. **Stretching and Exercise**: Scratching helps cats stretch their muscles, particularly in their shoulders and back. It also allows them to exercise and maintain their claws.\\n\\n3. **Stress Relief**: Scratching can be a way for cats to relieve stress or anxiety. It helps them release pent-up energy and express their emotions.\\n\\n4. **Maintaining Claws**: Scratching helps cats remove the outer sheath of their claws, keeping them healthy and sharp.\\n\\nTo prevent your cat from scratching furniture, you can try the following tips:\\n\\n1. **Provide Scratching Posts**: Offer your cat appropriate scratching surfaces like scratching posts or pads. Place them near the furniture your cat likes to scratch. You can try different materials like sisal, cardboard, or carpet to see what your cat prefers.\\n\\n2. **Positive Reinforcement**: Encourage your cat to use the scratching posts by rewarding them with treats or praise when they scratch the posts. You can also use toys to redirect their scratching behavior.\\n\\n3. **Trim Your Cat's Claws**: Regularly trimming your cat's claws can help reduce the damage caused by scratching. Be sure to use proper cat nail clippers and techniques to avoid hurting your cat.\\n\\n4. **Use Deterrents**: You can use double-sided tape, aluminum foil, or citrus scents on the furniture to deter your cat from scratching. Cats usually dislike the texture or smell of these substances.\\n\\n5. **Consult a Veterinarian**: If your cat's scratching behavior is excessive or sudden, it could be a sign of an underlying health issue or stress. In such cases, it's best to consult your veterinarian or a cat behaviorist for advice.\\n\\nRemember, it's essential to be patient and consistent when trying to modify your cat's scratching behavior. With the right approach and understanding of your cat's needs, you can help them redirect their scratching habits to more appropriate surfaces.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 450, 'prompt_tokens': 1549, 'total_tokens': 1999, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-2ed06a85-f0b2-4d2e-8611-abc8b719def6-0' usage_metadata={'input_tokens': 1549, 'output_tokens': 450, 'total_tokens': 1999, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from langchain.chat_models import ChatOpenAI  # Ensure ChatOpenAI is imported correctly\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv(\"apikey.env\")\n",
    "\n",
    "# Access the API key from environment variables\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY is missing. Please set it in your .env file.\")\n",
    "\n",
    "# Initialize ChatOpenAI model with the API key for chat-based models\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=api_key)\n",
    "\n",
    "# Initialize ChromaDB client and retrieve the collection\n",
    "client = chromadb.Client()\n",
    "collection = client.get_collection(\"cat_expert_knowledge\")\n",
    "\n",
    "# Initialize the embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Initialize a tokenizer to estimate token counts\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Limit context length by token count (e.g., 1500 tokens for context)\n",
    "MAX_CONTEXT_TOKENS = 1500\n",
    "\n",
    "# Multi-query generation: create multiple query variations\n",
    "def generate_query_variations(query):\n",
    "    \"\"\"Create variations of a query to enhance retrieval diversity.\"\"\"\n",
    "    return [\n",
    "        query,\n",
    "        f\"Explain about {query}\",\n",
    "        f\"How does {query} work?\",\n",
    "        f\"What are the details of {query}?\",\n",
    "        f\"Tell me more about {query}\"\n",
    "    ]\n",
    "\n",
    "# Updated retrieve_documents function with token count management\n",
    "def retrieve_documents(query):\n",
    "    query_variations = generate_query_variations(query)\n",
    "    results = []\n",
    "\n",
    "    for variation in query_variations:\n",
    "        query_embedding = embedding_model.encode(variation).tolist()\n",
    "        result = collection.query(query_embeddings=[query_embedding], n_results=2)\n",
    "        documents = [doc if isinstance(doc, str) else \" \".join(doc) for doc in result['documents']]\n",
    "        results.extend(documents)\n",
    "\n",
    "    # Combine all retrieved documents\n",
    "    full_context = \" \".join(results)\n",
    "\n",
    "    # Tokenize and truncate if the context exceeds the maximum token limit\n",
    "    tokens = tokenizer.encode(full_context)\n",
    "    if len(tokens) > MAX_CONTEXT_TOKENS:\n",
    "        tokens = tokens[:MAX_CONTEXT_TOKENS]\n",
    "        truncated_context = tokenizer.decode(tokens)\n",
    "    else:\n",
    "        truncated_context = full_context\n",
    "\n",
    "    return truncated_context\n",
    "\n",
    "# Define the LangChain ChatPromptTemplate with messages for chat models\n",
    "def create_qa_chain():\n",
    "    # Chat prompt template for structured input to chat model\n",
    "    template = \"\"\"You are a friendly, expert cat behaviorist inspired by Jackson Galaxy.\n",
    "Use the information below to answer the question comprehensively.\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", template),\n",
    "        (\"user\", \"{context}\\n\\nQuestion: {question}\\nAnswer:\")\n",
    "    ])\n",
    "\n",
    "    # Define the LLMChain with the chat prompt for generating answers\n",
    "    #return LLMChain(llm=llm, prompt=prompt)\n",
    "    return RunnableSequence(prompt | llm)\n",
    "\n",
    "# Main agent to respond to user queries\n",
    "context_history = []\n",
    "\n",
    "def ask_agent(query):\n",
    "    # Append the new question to context history\n",
    "    context_history.append(f\"Question: {query}\")\n",
    "    \n",
    "    # Retrieve relevant context from ChromaDB based on query variations\n",
    "    conversation_context = retrieve_documents(query)\n",
    "    \n",
    "    # Create QA chain with the generated context\n",
    "    qa_chain = create_qa_chain()\n",
    "    #answer = qa_chain.run({\"context\": conversation_context, \"question\": query})\n",
    "    answer = qa_chain.invoke({\"context\": conversation_context, \"question\": query})\n",
    "\n",
    "\n",
    "    # Append the answer to the context history for continuity\n",
    "    context_history.append(f\"Answer: {answer}\")\n",
    "    return answer\n",
    "\n",
    "# Test the agent with a sample query\n",
    "user_query = \"Why does my cat scratch furniture?\"\n",
    "response = ask_agent(user_query)\n",
    "print(\"Agent Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_chain():\n",
    "    # Chat prompt template for structured input to chat model\n",
    "    template = \"\"\"You are a friendly, expert cat behaviorist inspired by Jackson Galaxy.\n",
    "Use the information below to provide insightful and supportive advice as if speaking to a new cat owner.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer in a friendly and approachable manner:\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", template),\n",
    "        (\"user\", \"{context}\\n\\nQuestion: {question}\\nAnswer:\")\n",
    "    ])\n",
    "\n",
    "    # Define the LLMChain with the chat prompt for generating answers\n",
    "    return LLMChain(llm=llm, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main agent to respond to user queries with conversational memory\n",
    "def ask_agent(query):\n",
    "    # Append the new question to context history\n",
    "    context_history.append(f\"Question: {query}\")\n",
    "\n",
    "    # Retrieve relevant context from ChromaDB based on query variations\n",
    "    conversation_context = retrieve_documents(query)\n",
    "    \n",
    "    # Combine recent exchanges for conversational memory\n",
    "    recent_history = \"\\n\".join(context_history[-3:])  # Keep last 3 exchanges for continuity\n",
    "    combined_context = recent_history + \"\\n\\n\" + conversation_context\n",
    "    \n",
    "    # Create QA chain with the combined context\n",
    "    qa_chain = create_qa_chain()\n",
    "    answer = qa_chain.run({\"context\": combined_context, \"question\": query})\n",
    "\n",
    "    # Append the answer to the context history for continuity\n",
    "    context_history.append(f\"Answer: {answer}\")\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangSmith Check Point.\n",
    "\n",
    "This is only for review of how its working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks.manager import CallbackManager\n",
    "from langchain_core.callbacks.stdout import StdOutCallbackHandler\n",
    "\n",
    "\n",
    "# Initialize Tracer callback handler for LangChain's built-in tracing\n",
    "tracer_handler = StdOutCallbackHandler()\n",
    "\n",
    "# Attach the callback handler to a CallbackManager\n",
    "callback_manager = CallbackManager([tracer_handler])\n",
    "\n",
    "# Main agent function with LangChain tracing\n",
    "def ask_agent(query):\n",
    "    # Append the new question to context history\n",
    "    context_history.append(f\"Question: {query}\")\n",
    "\n",
    "    # Retrieve relevant context from ChromaDB based on query variations\n",
    "    conversation_context = retrieve_documents(query)\n",
    "    \n",
    "    # Combine recent exchanges for conversational memory\n",
    "    recent_history = \"\\n\".join(context_history[-3:])  # Keep last 3 exchanges for continuity\n",
    "    combined_context = recent_history + \"\\n\\n\" + conversation_context\n",
    "    \n",
    "    # Create QA chain with the combined context\n",
    "    qa_chain = create_qa_chain()\n",
    "\n",
    "    # Use callback_manager to log the QA chain run\n",
    "    answer = qa_chain.run(\n",
    "        {\"context\": combined_context, \"question\": query},\n",
    "        callbacks=callback_manager\n",
    "    )\n",
    "\n",
    "    # Append the answer to the context history for continuity\n",
    "    context_history.append(f\"Answer: {answer}\")\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install yt-dlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube:tab] Extracting URL: https://www.youtube.com/playlist?list=PLAJvHNBwbBNvSQFSeeHswdgIk2m4fljOc\n",
      "[youtube:tab] PLAJvHNBwbBNvSQFSeeHswdgIk2m4fljOc: Downloading webpage\n",
      "[youtube:tab] PLAJvHNBwbBNvSQFSeeHswdgIk2m4fljOc: Redownloading playlist API JSON with unavailable videos\n",
      "[download] Downloading playlist: INTRODUCTIONS\n",
      "[youtube:tab] PLAJvHNBwbBNvSQFSeeHswdgIk2m4fljOc page 1: Downloading API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube:tab] Incomplete data received. Retrying (1/3)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube:tab] PLAJvHNBwbBNvSQFSeeHswdgIk2m4fljOc page 1: Downloading API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube:tab] Incomplete data received. Retrying (2/3)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube:tab] PLAJvHNBwbBNvSQFSeeHswdgIk2m4fljOc page 1: Downloading API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube:tab] Incomplete data received. Retrying (3/3)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube:tab] PLAJvHNBwbBNvSQFSeeHswdgIk2m4fljOc page 1: Downloading API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube:tab] Incomplete data received. Giving up after 3 retries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube:tab] Playlist INTRODUCTIONS: Downloading 15 items of 15\n",
      "[download] Downloading item 1 of 15\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=ZUcVUFvmDFE\n",
      "[youtube] ZUcVUFvmDFE: Downloading webpage\n",
      "[youtube] ZUcVUFvmDFE: Downloading ios player API JSON\n",
      "[youtube] ZUcVUFvmDFE: Downloading mweb player API JSON\n",
      "[youtube] ZUcVUFvmDFE: Downloading m3u8 information\n",
      "[info] ZUcVUFvmDFE: Downloading 1 format(s): 616+251\n",
      "[download] path/to/save/videos/When Cat Introductions Get UGLY.webm has already been downloaded\n",
      "[download] Downloading item 2 of 15\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=4DlJYcfiRu4\n",
      "[youtube] 4DlJYcfiRu4: Downloading webpage\n",
      "[youtube] 4DlJYcfiRu4: Downloading ios player API JSON\n",
      "[youtube] 4DlJYcfiRu4: Downloading mweb player API JSON\n",
      "[youtube] 4DlJYcfiRu4: Downloading m3u8 information\n",
      "[info] 4DlJYcfiRu4: Downloading 1 format(s): 616+251\n",
      "[download] path/to/save/videos/How To Introduce Your Cat to a New KITTEN!.webm has already been downloaded\n",
      "[download] Downloading item 3 of 15\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=rxInrRQLEmM\n",
      "[youtube] rxInrRQLEmM: Downloading webpage\n",
      "[youtube] rxInrRQLEmM: Downloading ios player API JSON\n",
      "[youtube] rxInrRQLEmM: Downloading mweb player API JSON\n",
      "[youtube] rxInrRQLEmM: Downloading m3u8 information\n",
      "[info] rxInrRQLEmM: Downloading 1 format(s): 616+251\n",
      "[download] path/to/save/videos/Can Cats & Dogs Be Friendsï¼Ÿ ï½œ Jackson Galaxy.webm has already been downloaded\n",
      "[download] Downloading item 4 of 15\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=-OmMDhK2FxQ\n",
      "[youtube] -OmMDhK2FxQ: Downloading webpage\n",
      "[youtube] -OmMDhK2FxQ: Downloading ios player API JSON\n",
      "[youtube] -OmMDhK2FxQ: Downloading mweb player API JSON\n",
      "[youtube] -OmMDhK2FxQ: Downloading m3u8 information\n",
      "[info] -OmMDhK2FxQ: Downloading 1 format(s): 137+251\n",
      "[download] path/to/save/videos/Non-Recognition Aggression in Cats Explained.mkv has already been downloaded\n",
      "[download] Downloading item 5 of 15\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=gxlNfh5ukMw\n",
      "[youtube] gxlNfh5ukMw: Downloading webpage\n",
      "[youtube] gxlNfh5ukMw: Downloading ios player API JSON\n",
      "[youtube] gxlNfh5ukMw: Downloading mweb player API JSON\n",
      "[youtube] gxlNfh5ukMw: Downloading m3u8 information\n",
      "[info] gxlNfh5ukMw: Downloading 1 format(s): 616+251\n",
      "[download] path/to/save/videos/Cat Introductions Gone Wrongï¼š They Will NOT Work it Out Without You.webm has already been downloaded\n",
      "[download] Downloading item 6 of 15\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=ojS7XwtoXtw\n",
      "[youtube] ojS7XwtoXtw: Downloading webpage\n",
      "[youtube] ojS7XwtoXtw: Downloading ios player API JSON\n",
      "[youtube] ojS7XwtoXtw: Downloading mweb player API JSON\n",
      "[youtube] ojS7XwtoXtw: Downloading m3u8 information\n",
      "[info] ojS7XwtoXtw: Downloading 1 format(s): 616+251\n",
      "[download] path/to/save/videos/Cat Introductionsï¼š Good First Impressions are a must!.webm has already been downloaded\n",
      "[download] Downloading item 7 of 15\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=tsYT7yIOdqQ\n",
      "[youtube] tsYT7yIOdqQ: Downloading webpage\n",
      "[youtube] tsYT7yIOdqQ: Downloading ios player API JSON\n",
      "[youtube] tsYT7yIOdqQ: Downloading mweb player API JSON\n",
      "[youtube] tsYT7yIOdqQ: Downloading m3u8 information\n",
      "[info] tsYT7yIOdqQ: Downloading 1 format(s): 616+251\n",
      "[download] path/to/save/videos/How to Introduce Cats.webm has already been downloaded\n",
      "[download] Downloading item 8 of 15\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=UWohxDOXsl4\n",
      "[youtube] UWohxDOXsl4: Downloading webpage\n",
      "[youtube] UWohxDOXsl4: Downloading ios player API JSON\n",
      "[youtube] UWohxDOXsl4: Downloading mweb player API JSON\n",
      "[youtube] UWohxDOXsl4: Downloading m3u8 information\n",
      "[info] UWohxDOXsl4: Downloading 1 format(s): 616+251\n",
      "[download] path/to/save/videos/Can my Cats Get Alongï¼Ÿ Cat-to-Cat Body Language basics & Introduction Tips.webm has already been downloaded\n",
      "[download] Downloading item 9 of 15\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=gZrwcoiy_gY\n",
      "[youtube] gZrwcoiy_gY: Downloading webpage\n",
      "[youtube] gZrwcoiy_gY: Downloading ios player API JSON\n",
      "[youtube] gZrwcoiy_gY: Downloading mweb player API JSON\n",
      "[youtube] gZrwcoiy_gY: Downloading m3u8 information\n",
      "[info] gZrwcoiy_gY: Downloading 1 format(s): 398+140\n",
      "[download] path/to/save/videos/The Best Way To Introduce Your Two Cats.mp4 has already been downloaded\n",
      "[download] Downloading item 10 of 15\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=lSDI5diNu4Y\n",
      "[youtube] lSDI5diNu4Y: Downloading webpage\n",
      "[youtube] lSDI5diNu4Y: Downloading ios player API JSON\n",
      "[youtube] lSDI5diNu4Y: Downloading mweb player API JSON\n",
      "[youtube] lSDI5diNu4Y: Downloading m3u8 information\n",
      "[info] lSDI5diNu4Y: Downloading 1 format(s): 137+251\n",
      "[download] path/to/save/videos/The Do's & Don'ts of Introducing Cats.mkv has already been downloaded\n",
      "[download] Downloading item 11 of 15\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=8aCGL9GpVUg\n",
      "[youtube] 8aCGL9GpVUg: Downloading webpage\n",
      "[youtube] 8aCGL9GpVUg: Downloading ios player API JSON\n",
      "[youtube] 8aCGL9GpVUg: Downloading mweb player API JSON\n",
      "[youtube] 8aCGL9GpVUg: Downloading m3u8 information\n",
      "[info] 8aCGL9GpVUg: Downloading 1 format(s): 137+251\n",
      "[download] path/to/save/videos/Cat Introductionsï¼š Does your Senior Need A Friendï¼Ÿ.mkv has already been downloaded\n",
      "[download] Downloading item 12 of 15\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=VjOXvD7OvrE\n",
      "[youtube] VjOXvD7OvrE: Downloading webpage\n",
      "[youtube] VjOXvD7OvrE: Downloading ios player API JSON\n",
      "[youtube] VjOXvD7OvrE: Downloading mweb player API JSON\n",
      "[youtube] VjOXvD7OvrE: Downloading m3u8 information\n",
      "[info] VjOXvD7OvrE: Downloading 1 format(s): 616+251\n",
      "[download] path/to/save/videos/This was BAD!! ðŸ™€ðŸ¤¯ðŸ«£ #shorts.webm has already been downloaded\n",
      "[download] Downloading item 13 of 15\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=FzifwTnCV5s\n",
      "[youtube] FzifwTnCV5s: Downloading webpage\n",
      "[youtube] FzifwTnCV5s: Downloading ios player API JSON\n",
      "[youtube] FzifwTnCV5s: Downloading mweb player API JSON\n",
      "[youtube] FzifwTnCV5s: Downloading m3u8 information\n",
      "[info] FzifwTnCV5s: Downloading 1 format(s): 616+251\n",
      "[download] path/to/save/videos/Why You Should Get Another Cat.webm has already been downloaded\n",
      "[download] Downloading item 14 of 15\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=XreeFU7RYeI\n",
      "[youtube] XreeFU7RYeI: Downloading webpage\n",
      "[youtube] XreeFU7RYeI: Downloading ios player API JSON\n",
      "[youtube] XreeFU7RYeI: Downloading mweb player API JSON\n",
      "[youtube] XreeFU7RYeI: Downloading m3u8 information\n",
      "[info] XreeFU7RYeI: Downloading 1 format(s): 616+251\n",
      "[download] path/to/save/videos/Are My Cats Playing or Fightingï¼Ÿ ï½œ Cat Playing vs Cat Aggression.webm has already been downloaded\n",
      "[download] Downloading item 15 of 15\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=-4O97jw_8Bc\n",
      "[youtube] -4O97jw_8Bc: Downloading webpage\n",
      "[youtube] -4O97jw_8Bc: Downloading ios player API JSON\n",
      "[youtube] -4O97jw_8Bc: Downloading mweb player API JSON\n",
      "[youtube] -4O97jw_8Bc: Downloading m3u8 information\n",
      "[info] -4O97jw_8Bc: Downloading 1 format(s): 616+251\n",
      "[download] path/to/save/videos/Brady Bunchingï¼š Introducing Two Groups of Cats.webm has already been downloaded\n",
      "[download] Finished downloading playlist: INTRODUCTIONS\n",
      "Videos have been successfully downloaded.\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "import os\n",
    "\n",
    "# Define the playlist URL and output path for saving video files\n",
    "playlist_url = \"https://www.youtube.com/playlist?list=PLAJvHNBwbBNvSQFSeeHswdgIk2m4fljOc\"  # Replace with actual playlist URL\n",
    "output_path = \"path/to/save/videos/%(title)s.%(ext)s\"  # Directory to save videos\n",
    "\n",
    "# Set yt-dlp options for downloading video\n",
    "ydl_opts = {\n",
    "    'format': 'bestvideo+bestaudio',  # Downloads the best quality video and audio\n",
    "    'outtmpl': output_path,           # Sets the output path and filename format\n",
    "    'ignoreerrors': True,             # Skip any videos that cause errors\n",
    "}\n",
    "\n",
    "# Download videos from the specified playlist\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([playlist_url])\n",
    "\n",
    "print(\"Videos have been successfully downloaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import LangSmithCallbackHandler\n",
    "from langchain.callbacks import CallbackManager\n",
    "\n",
    "# Initialize LangSmith callback handler\n",
    "langsmith_handler = LangSmithCallbackHandler(\n",
    "    project_name=\"Cat Behavior Chatbot\",\n",
    "    tags=[\"production\", \"chatbot\"]\n",
    ")\n",
    "\n",
    "# Attach the callback handler to a CallbackManager\n",
    "callback_manager = CallbackManager([langsmith_handler])\n",
    "\n",
    "# Update `ask_agent` to use callback for logging\n",
    "def ask_agent(query, user_id=\"default_user\"):\n",
    "    # Get user profile and preferred response length\n",
    "    profile = get_user_profile(user_id)\n",
    "    \n",
    "    # Detect intent and set response type accordingly\n",
    "    intent = detect_intent(query)\n",
    "    response_length = profile[\"preferred_response_length\"] if intent != \"concise\" else \"concise\"\n",
    "    \n",
    "    # Manage memory based on user preferences and recent interactions\n",
    "    conversation_context = manage_memory(query, user_id)\n",
    "    \n",
    "    # Retrieve relevant context and images if intent is \"visual_example\"\n",
    "    if intent == \"visual_example\":\n",
    "        relevant_texts, relevant_images = retrieve_documents(query)\n",
    "    else:\n",
    "        relevant_texts, _ = retrieve_documents(query)\n",
    "        relevant_images = []\n",
    "\n",
    "    # Combine text responses\n",
    "    text_response = \" \".join([text[\"metadata\"][\"text\"] for text in relevant_texts])\n",
    "\n",
    "    # Create a customized response based on intent and user preferences\n",
    "    response = f\"**{profile['name']}'s Personalized Advice:**\\n{text_response}\"\n",
    "    if intent == \"visual_example\" and relevant_images:\n",
    "        response += \"\\n\\n**Visual References:**\\n\" + \"\\n\".join(relevant_images)\n",
    "\n",
    "    # Append answer to user-specific history\n",
    "    get_user_history(user_id).append(f\"Question: {query}\\nAnswer: {response}\")\n",
    "    \n",
    "    # Run with callbacks for LangSmith logging\n",
    "    callback_manager.on_text(query)\n",
    "    callback_manager.on_text(response)\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Extract Key Frames from Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Extract frames from each video\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video_file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(video_dir):\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mextract_key_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 23\u001b[0m, in \u001b[0;36mextract_key_frames\u001b[0;34m(video_path, output_folder, intervals)\u001b[0m\n\u001b[1;32m     21\u001b[0m         frame_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_frame_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mimwrite(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, frame_name), frame)\n\u001b[0;32m---> 23\u001b[0m     success, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcapture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     25\u001b[0m capture\u001b[38;5;241m.\u001b[39mrelease()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Directory containing videos\n",
    "video_dir = \"/notebooks/path/to/save/videos\"\n",
    "frame_dir = \"path/to/frames\"\n",
    "\n",
    "os.makedirs(frame_dir, exist_ok=True)\n",
    "\n",
    "def extract_key_frames(video_path, output_folder, intervals=60):\n",
    "    \"\"\"Extract frames at given intervals (in seconds) from a video.\"\"\"\n",
    "    video_name = os.path.basename(video_path).split('.')[0]\n",
    "    capture = cv2.VideoCapture(video_path)\n",
    "    fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "    interval_frames = int(fps * intervals)\n",
    "\n",
    "    success, frame = capture.read()\n",
    "    count = 0\n",
    "    while success:\n",
    "        if count % interval_frames == 0:\n",
    "            frame_name = f\"{video_name}_frame_{count}.jpg\"\n",
    "            cv2.imwrite(os.path.join(output_folder, frame_name), frame)\n",
    "        success, frame = capture.read()\n",
    "        count += 1\n",
    "    capture.release()\n",
    "\n",
    "# Extract frames from each video\n",
    "for video_file in os.listdir(video_dir):\n",
    "    extract_key_frames(os.path.join(video_dir, video_file), frame_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed and Store Visualy with Clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "%pip install langsmith\n",
    "%pip install --upgrade --quiet  langchain-experimental\n",
    "%pip install --upgrade --quiet  pillow open_clip_torch torch matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RN50', 'openai'),\n",
       " ('RN50', 'yfcc15m'),\n",
       " ('RN50', 'cc12m'),\n",
       " ('RN101', 'openai'),\n",
       " ('RN101', 'yfcc15m'),\n",
       " ('RN50x4', 'openai'),\n",
       " ('RN50x16', 'openai'),\n",
       " ('RN50x64', 'openai'),\n",
       " ('ViT-B-32', 'openai'),\n",
       " ('ViT-B-32', 'laion400m_e31'),\n",
       " ('ViT-B-32', 'laion400m_e32'),\n",
       " ('ViT-B-32', 'laion2b_e16'),\n",
       " ('ViT-B-32', 'laion2b_s34b_b79k'),\n",
       " ('ViT-B-32', 'datacomp_xl_s13b_b90k'),\n",
       " ('ViT-B-32', 'datacomp_m_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_clip_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_laion_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_image_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_text_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_basic_s128m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_m_s128m_b4k'),\n",
       " ('ViT-B-32', 'datacomp_s_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_clip_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_laion_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_image_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_text_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_basic_s13m_b4k'),\n",
       " ('ViT-B-32', 'commonpool_s_s13m_b4k'),\n",
       " ('ViT-B-32', 'metaclip_400m'),\n",
       " ('ViT-B-32', 'metaclip_fullcc'),\n",
       " ('ViT-B-32-256', 'datacomp_s34b_b86k'),\n",
       " ('ViT-B-16', 'openai'),\n",
       " ('ViT-B-16', 'laion400m_e31'),\n",
       " ('ViT-B-16', 'laion400m_e32'),\n",
       " ('ViT-B-16', 'laion2b_s34b_b88k'),\n",
       " ('ViT-B-16', 'datacomp_xl_s13b_b90k'),\n",
       " ('ViT-B-16', 'datacomp_l_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_clip_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_laion_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_image_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_text_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_basic_s1b_b8k'),\n",
       " ('ViT-B-16', 'commonpool_l_s1b_b8k'),\n",
       " ('ViT-B-16', 'dfn2b'),\n",
       " ('ViT-B-16', 'metaclip_400m'),\n",
       " ('ViT-B-16', 'metaclip_fullcc'),\n",
       " ('ViT-B-16-plus-240', 'laion400m_e31'),\n",
       " ('ViT-B-16-plus-240', 'laion400m_e32'),\n",
       " ('ViT-L-14', 'openai'),\n",
       " ('ViT-L-14', 'laion400m_e31'),\n",
       " ('ViT-L-14', 'laion400m_e32'),\n",
       " ('ViT-L-14', 'laion2b_s32b_b82k'),\n",
       " ('ViT-L-14', 'datacomp_xl_s13b_b90k'),\n",
       " ('ViT-L-14', 'commonpool_xl_clip_s13b_b90k'),\n",
       " ('ViT-L-14', 'commonpool_xl_laion_s13b_b90k'),\n",
       " ('ViT-L-14', 'commonpool_xl_s13b_b90k'),\n",
       " ('ViT-L-14', 'metaclip_400m'),\n",
       " ('ViT-L-14', 'metaclip_fullcc'),\n",
       " ('ViT-L-14', 'dfn2b'),\n",
       " ('ViT-L-14-336', 'openai'),\n",
       " ('ViT-H-14', 'laion2b_s32b_b79k'),\n",
       " ('ViT-H-14', 'metaclip_fullcc'),\n",
       " ('ViT-H-14', 'dfn5b'),\n",
       " ('ViT-H-14-378', 'dfn5b'),\n",
       " ('ViT-g-14', 'laion2b_s12b_b42k'),\n",
       " ('ViT-g-14', 'laion2b_s34b_b88k'),\n",
       " ('ViT-bigG-14', 'laion2b_s39b_b160k'),\n",
       " ('ViT-bigG-14', 'metaclip_fullcc'),\n",
       " ('roberta-ViT-B-32', 'laion2b_s12b_b32k'),\n",
       " ('xlm-roberta-base-ViT-B-32', 'laion5b_s13b_b90k'),\n",
       " ('xlm-roberta-large-ViT-H-14', 'frozen_laion5b_s13b_b90k'),\n",
       " ('convnext_base', 'laion400m_s13b_b51k'),\n",
       " ('convnext_base_w', 'laion2b_s13b_b82k'),\n",
       " ('convnext_base_w', 'laion2b_s13b_b82k_augreg'),\n",
       " ('convnext_base_w', 'laion_aesthetic_s13b_b82k'),\n",
       " ('convnext_base_w_320', 'laion_aesthetic_s13b_b82k'),\n",
       " ('convnext_base_w_320', 'laion_aesthetic_s13b_b82k_augreg'),\n",
       " ('convnext_large_d', 'laion2b_s26b_b102k_augreg'),\n",
       " ('convnext_large_d_320', 'laion2b_s29b_b131k_ft'),\n",
       " ('convnext_large_d_320', 'laion2b_s29b_b131k_ft_soup'),\n",
       " ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg'),\n",
       " ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg_rewind'),\n",
       " ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg_soup'),\n",
       " ('coca_ViT-B-32', 'laion2b_s13b_b90k'),\n",
       " ('coca_ViT-B-32', 'mscoco_finetuned_laion2b_s13b_b90k'),\n",
       " ('coca_ViT-L-14', 'laion2b_s13b_b90k'),\n",
       " ('coca_ViT-L-14', 'mscoco_finetuned_laion2b_s13b_b90k'),\n",
       " ('EVA01-g-14', 'laion400m_s11b_b41k'),\n",
       " ('EVA01-g-14-plus', 'merged2b_s11b_b114k'),\n",
       " ('EVA02-B-16', 'merged2b_s8b_b131k'),\n",
       " ('EVA02-L-14', 'merged2b_s4b_b131k'),\n",
       " ('EVA02-L-14-336', 'merged2b_s6b_b61k'),\n",
       " ('EVA02-E-14', 'laion2b_s4b_b115k'),\n",
       " ('EVA02-E-14-plus', 'laion2b_s9b_b144k'),\n",
       " ('ViT-B-16-SigLIP', 'webli'),\n",
       " ('ViT-B-16-SigLIP-256', 'webli'),\n",
       " ('ViT-B-16-SigLIP-i18n-256', 'webli'),\n",
       " ('ViT-B-16-SigLIP-384', 'webli'),\n",
       " ('ViT-B-16-SigLIP-512', 'webli'),\n",
       " ('ViT-L-16-SigLIP-256', 'webli'),\n",
       " ('ViT-L-16-SigLIP-384', 'webli'),\n",
       " ('ViT-SO400M-14-SigLIP', 'webli'),\n",
       " ('ViT-SO400M-16-SigLIP-i18n-256', 'webli'),\n",
       " ('ViT-SO400M-14-SigLIP-378', 'webli'),\n",
       " ('ViT-SO400M-14-SigLIP-384', 'webli'),\n",
       " ('ViT-L-14-CLIPA', 'datacomp1b'),\n",
       " ('ViT-L-14-CLIPA-336', 'datacomp1b'),\n",
       " ('ViT-H-14-CLIPA', 'datacomp1b'),\n",
       " ('ViT-H-14-CLIPA-336', 'laion2b'),\n",
       " ('ViT-H-14-CLIPA-336', 'datacomp1b'),\n",
       " ('ViT-bigG-14-CLIPA', 'datacomp1b'),\n",
       " ('ViT-bigG-14-CLIPA-336', 'datacomp1b'),\n",
       " ('nllb-clip-base', 'v1'),\n",
       " ('nllb-clip-large', 'v1'),\n",
       " ('nllb-clip-base-siglip', 'v1'),\n",
       " ('nllb-clip-base-siglip', 'mrl'),\n",
       " ('nllb-clip-large-siglip', 'v1'),\n",
       " ('nllb-clip-large-siglip', 'mrl'),\n",
       " ('MobileCLIP-S1', 'datacompdr'),\n",
       " ('MobileCLIP-S2', 'datacompdr'),\n",
       " ('MobileCLIP-B', 'datacompdr'),\n",
       " ('MobileCLIP-B', 'datacompdr_lt'),\n",
       " ('ViTamin-S', 'datacomp1b'),\n",
       " ('ViTamin-S-LTT', 'datacomp1b'),\n",
       " ('ViTamin-B', 'datacomp1b'),\n",
       " ('ViTamin-B-LTT', 'datacomp1b'),\n",
       " ('ViTamin-L', 'datacomp1b'),\n",
       " ('ViTamin-L-256', 'datacomp1b'),\n",
       " ('ViTamin-L-336', 'datacomp1b'),\n",
       " ('ViTamin-L-384', 'datacomp1b'),\n",
       " ('ViTamin-L2', 'datacomp1b'),\n",
       " ('ViTamin-L2-256', 'datacomp1b'),\n",
       " ('ViTamin-L2-336', 'datacomp1b'),\n",
       " ('ViTamin-L2-384', 'datacomp1b'),\n",
       " ('ViTamin-XL-256', 'datacomp1b'),\n",
       " ('ViTamin-XL-336', 'datacomp1b'),\n",
       " ('ViTamin-XL-384', 'datacomp1b'),\n",
       " ('RN50-quickgelu', 'openai'),\n",
       " ('RN50-quickgelu', 'yfcc15m'),\n",
       " ('RN50-quickgelu', 'cc12m'),\n",
       " ('RN101-quickgelu', 'openai'),\n",
       " ('RN101-quickgelu', 'yfcc15m'),\n",
       " ('RN50x4-quickgelu', 'openai'),\n",
       " ('RN50x16-quickgelu', 'openai'),\n",
       " ('RN50x64-quickgelu', 'openai'),\n",
       " ('ViT-B-32-quickgelu', 'openai'),\n",
       " ('ViT-B-32-quickgelu', 'laion400m_e31'),\n",
       " ('ViT-B-32-quickgelu', 'laion400m_e32'),\n",
       " ('ViT-B-32-quickgelu', 'metaclip_400m'),\n",
       " ('ViT-B-32-quickgelu', 'metaclip_fullcc'),\n",
       " ('ViT-B-16-quickgelu', 'openai'),\n",
       " ('ViT-B-16-quickgelu', 'dfn2b'),\n",
       " ('ViT-B-16-quickgelu', 'metaclip_400m'),\n",
       " ('ViT-B-16-quickgelu', 'metaclip_fullcc'),\n",
       " ('ViT-L-14-quickgelu', 'openai'),\n",
       " ('ViT-L-14-quickgelu', 'metaclip_400m'),\n",
       " ('ViT-L-14-quickgelu', 'metaclip_fullcc'),\n",
       " ('ViT-L-14-quickgelu', 'dfn2b'),\n",
       " ('ViT-L-14-336-quickgelu', 'openai'),\n",
       " ('ViT-H-14-quickgelu', 'metaclip_fullcc'),\n",
       " ('ViT-H-14-quickgelu', 'dfn5b'),\n",
       " ('ViT-H-14-378-quickgelu', 'dfn5b'),\n",
       " ('ViT-bigG-14-quickgelu', 'metaclip_fullcc')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import open_clip\n",
    "\n",
    "open_clip.list_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ViT-g-14\"\n",
    "checkpoint = \"laion2b_s34b_b88k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f518797d2ab4582b626eccb392d9063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "open_clip_pytorch_model.bin:   0%|          | 0.00/5.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from langchain_experimental.open_clip import OpenCLIPEmbeddings\n",
    "from PIL import Image\n",
    "\n",
    "# Initialize the OpenCLIP embedding model\n",
    "clip_embd = OpenCLIPEmbeddings(model_name=\"ViT-g-14\", checkpoint=\"laion2b_s34b_b88k\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Embeddings for Text and Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text documents\n",
    "text_documents = [\n",
    "    {\"id\": \"1\", \"text\": \"How to reduce cat scratching behavior\", \"topic\": \"behavior\"},\n",
    "    {\"id\": \"2\", \"text\": \"Creating a cat-friendly environment\", \"topic\": \"environment\"}\n",
    "]\n",
    "\n",
    "# Embed and store text embeddings\n",
    "text_embeddings = []\n",
    "for doc in text_documents:\n",
    "    embedding = clip_embd.embed_documents([doc['text']])\n",
    "    text_embeddings.append({\n",
    "        \"id\": doc[\"id\"],\n",
    "        \"embedding\": embedding,\n",
    "        \"metadata\": {\"topic\": doc[\"topic\"], \"text\": doc[\"text\"]}\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the directory for frames\n",
    "frame_dir = \"/notebooks/path/to/frames\"\n",
    "os.makedirs(frame_dir, exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "# Example for embedding and storing image embeddings\n",
    "from langchain_experimental.open_clip import OpenCLIPEmbeddings\n",
    "from PIL import Image\n",
    "\n",
    "# Initialize OpenCLIP embeddings\n",
    "clip_embd = OpenCLIPEmbeddings(model_name=\"ViT-g-14\", checkpoint=\"laion2b_s34b_b88k\")\n",
    "\n",
    "# Embed and store image embeddings\n",
    "image_embeddings = []\n",
    "for frame_file in os.listdir(frame_dir):\n",
    "    frame_path = os.path.join(frame_dir, frame_file)\n",
    "    image = Image.open(frame_path)\n",
    "    embedding = clip_embd.embed_image([frame_path])  # Embed using the new path\n",
    "    image_embeddings.append({\n",
    "        \"id\": frame_file,\n",
    "        \"embedding\": embedding,\n",
    "        \"metadata\": {\"topic\": \"visual\", \"source\": frame_path}\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image file paths\n",
    "#image_files = [\"/notebooks/path/to/frames/Non-Recognition Aggression in Cats Explained_frame_0.jpg\", \n",
    " #              \"/notebooks/path/to/frames/Non-Recognition Aggression in Cats Explained_frame_1438.jpg\"]\n",
    "\n",
    "# Embed and store image embeddings\n",
    "#image_embeddings = []\n",
    "#for img_path in image_files:\n",
    "#    embedding = clip_embd.embed_image([img_path])\n",
    "#    image_embeddings.append({\n",
    "#        \"id\": img_path,\n",
    "#        \"embedding\": embedding,\n",
    "#        \"metadata\": {\"topic\": \"visual\", \"source\": img_path}\n",
    "#    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store Embeddings and Perform Retrieval:\n",
    "Since LangSmith doesnâ€™t yet support a full embedding storage and retrieval service like ChromaDB, weâ€™ll use numpy to store and retrieve embeddings locally. This will simulate a vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store embeddings in separate lists for text and images\n",
    "text_store = {entry[\"id\"]: entry for entry in text_embeddings}\n",
    "image_store = {entry[\"id\"]: entry for entry in image_embeddings}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def retrieve_similar_embeddings(query, store, top_k=2):\n",
    "    \"\"\"Retrieve top K similar embeddings from the store.\"\"\"\n",
    "    query_embedding = clip_embd.embed_documents([query])\n",
    "    similarities = []\n",
    "\n",
    "    for item in store.values():\n",
    "        score = cosine_similarity(query_embedding, item[\"embedding\"]).flatten()[0]\n",
    "        similarities.append((score, item))\n",
    "\n",
    "    # Sort by similarity and select top K results\n",
    "    similarities = sorted(similarities, key=lambda x: x[0], reverse=True)\n",
    "    return [item for _, item in similarities[:top_k]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update LangChain Agent for Multimodal Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response: Creating a cat-friendly environment How to reduce cat scratching behavior\n",
      "\n",
      "Visual references available:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def ask_agent(query):\n",
    "    # Retrieve similar text and image embeddings\n",
    "    relevant_texts = retrieve_similar_embeddings(query, text_store)\n",
    "    relevant_images = retrieve_similar_embeddings(query, image_store)\n",
    "    \n",
    "    # Combine text responses\n",
    "    text_response = \" \".join([text[\"metadata\"][\"text\"] for text in relevant_texts])\n",
    "    \n",
    "    # Prepare image references for output\n",
    "    image_references = \"\\n\".join([image[\"metadata\"][\"source\"] for image in relevant_images])\n",
    "\n",
    "    # Final response with text and image references\n",
    "    response = f\"{text_response}\\n\\nVisual references available:\\n{image_references}\"\n",
    "    return response\n",
    "\n",
    "# Test the agent with a sample query\n",
    "user_query = \"How can I create a cat-friendly environment?\"\n",
    "response = ask_agent(user_query)\n",
    "print(\"Agent Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_agent(query):\n",
    "    # Append the new question to context history\n",
    "    context_history.append(f\"Question: {query}\")\n",
    "\n",
    "    # Retrieve relevant context and images from ChromaDB based on query variations\n",
    "    conversation_context, images = retrieve_documents(query)\n",
    "    \n",
    "    # Combine recent exchanges for conversational memory\n",
    "    recent_history = \"\\n\".join(context_history[-3:])\n",
    "    combined_context = recent_history + \"\\n\\n\" + conversation_context\n",
    "    \n",
    "    # Create QA chain with the combined context\n",
    "    qa_chain = create_qa_chain()\n",
    "    answer = qa_chain.run({\"context\": combined_context, \"question\": query})\n",
    "\n",
    "    # Append the answer to the context history for continuity\n",
    "    context_history.append(f\"Answer: {answer}\")\n",
    "    \n",
    "    # Present images in the response if available\n",
    "    if images:\n",
    "        answer += \"\\nVisual references available:\\n\" + \"\\n\".join(images)\n",
    "\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Multimodal Retrieval and Response Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response: **Expert Advice:**\n",
      "Creating a cat-friendly environment How to reduce cat scratching behavior\n",
      "\n",
      "**Visual References:**\n",
      "No visual references available.\n"
     ]
    }
   ],
   "source": [
    "def ask_agent(query):\n",
    "    # Retrieve similar text and image embeddings\n",
    "    relevant_texts = retrieve_similar_embeddings(query, text_store)\n",
    "    relevant_images = retrieve_similar_embeddings(query, image_store)\n",
    "    \n",
    "    # Combine text responses\n",
    "    text_response = \" \".join([text[\"metadata\"][\"text\"] for text in relevant_texts])\n",
    "    \n",
    "    # Prepare image references for output\n",
    "    image_references = \"\\n\".join([image[\"metadata\"][\"source\"] for image in relevant_images])\n",
    "\n",
    "    # Final response with formatted sections\n",
    "    response = (\n",
    "        f\"**Expert Advice:**\\n{text_response}\\n\\n\"\n",
    "        f\"**Visual References:**\\n{image_references if image_references else 'No visual references available.'}\"\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# Test the agent with a sample query\n",
    "user_query = \"How can I create a cat-friendly environment?\"\n",
    "response = ask_agent(user_query)\n",
    "print(\"Agent Response:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a Feedback Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response: **Expert Advice:**\n",
      "How to reduce cat scratching behavior Creating a cat-friendly environment\n",
      "\n",
      "**Visual References:**\n",
      "No visual references available.\n",
      "Rate the helpfulness of the response (1-5):\n",
      "Thank you for your feedback!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define a function to log feedback\n",
    "feedback_log = \"feedback_log.json\"  # Path to store feedback\n",
    "\n",
    "def log_feedback(query, response, rating, comment=None):\n",
    "    feedback_entry = {\n",
    "        \"query\": query,\n",
    "        \"response\": response,\n",
    "        \"rating\": rating,\n",
    "        \"comment\": comment\n",
    "    }\n",
    "    \n",
    "    # Append feedback to a JSON file\n",
    "    try:\n",
    "        with open(feedback_log, \"a\") as f:\n",
    "            f.write(json.dumps(feedback_entry) + \"\\n\")\n",
    "    except IOError:\n",
    "        print(\"Error logging feedback.\")\n",
    "\n",
    "# Collect feedback from the user\n",
    "def collect_feedback(query, response):\n",
    "    print(\"Rate the helpfulness of the response (1-5):\")\n",
    "    rating = int(input(\"Rating: \"))\n",
    "    comment = input(\"Any comments? \")\n",
    "    \n",
    "    # Log the feedback\n",
    "    log_feedback(query, response, rating, comment)\n",
    "    print(\"Thank you for your feedback!\")\n",
    "\n",
    "# Test the agent with feedback\n",
    "user_query = \"Why does my cat scratch furniture?\"\n",
    "response = ask_agent(user_query)\n",
    "print(\"Agent Response:\", response)\n",
    "\n",
    "# Collect feedback from user\n",
    "collect_feedback(user_query, response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Personalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store user profiles\n",
    "user_profiles = {}\n",
    "\n",
    "# Function to initialize or update a user profile\n",
    "def get_user_profile(user_id):\n",
    "    if user_id not in user_profiles:\n",
    "        user_profiles[user_id] = {\n",
    "            \"name\": \"User\",\n",
    "            \"preferred_response_length\": \"detailed\",  # or 'concise'\n",
    "            \"interest_areas\": [\"behavior\", \"environment\"]\n",
    "        }\n",
    "    return user_profiles[user_id]\n",
    "\n",
    "# Function to update profile details\n",
    "def update_user_profile(user_id, name=None, response_length=None, interests=None):\n",
    "    profile = get_user_profile(user_id)\n",
    "    if name:\n",
    "        profile[\"name\"] = name\n",
    "    if response_length:\n",
    "        profile[\"preferred_response_length\"] = response_length\n",
    "    if interests:\n",
    "        profile[\"interest_areas\"] = interests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Memory Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit memory length to relevant recent exchanges\n",
    "def manage_memory(query, user_id, max_exchanges=3):\n",
    "    profile = get_user_profile(user_id)\n",
    "    relevant_context = \"\\n\".join([context for context in context_history[-max_exchanges:] \n",
    "                                  if any(area in context for area in profile[\"interest_areas\"])])\n",
    "    return relevant_context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weâ€™ll add a simple intent classification to help the chatbot recognize and respond to different types of user intents. Basic intents might include requests for:\n",
    "\n",
    "Advice: General guidance or recommendations.\n",
    "Visual Examples: Requests for images or visual aids.\n",
    "Detailed Explanations: In-depth responses for complex questions.\n",
    "Define Intent Detection\n",
    "For simplicity, weâ€™ll use keywords to detect intents. For more robust intent classification, you could use a trained NLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect user intent based on keywords\n",
    "def detect_intent(query):\n",
    "    query = query.lower()\n",
    "    if any(word in query for word in [\"how\", \"what\", \"why\"]):\n",
    "        return \"advice\"\n",
    "    elif any(word in query for word in [\"show\", \"picture\", \"visual\", \"image\"]):\n",
    "        return \"visual_example\"\n",
    "    elif any(word in query for word in [\"explain\", \"detailed\", \"in-depth\"]):\n",
    "        return \"detailed_explanation\"\n",
    "    else:\n",
    "        return \"advice\"  # Default intent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify ask_agent to Use Personalization, Memory Management, and Intent Handling\n",
    "Update the main function to:\n",
    "\n",
    "Retrieve the userâ€™s profile.\n",
    "Use the detected intent to adjust the response.\n",
    "Apply memory management to provide relevant context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Mock storage for embeddings (use actual embeddings in a real setup)\n",
    "text_store = {}\n",
    "image_store = {}\n",
    "\n",
    "# Define `retrieve_documents` function\n",
    "def retrieve_documents(query, top_k=2):\n",
    "    # Embed the query using the same embedding function used for storing text and images\n",
    "    query_embedding = clip_embd.embed_documents([query])\n",
    "    \n",
    "    # Retrieve text embeddings\n",
    "    text_results = []\n",
    "    for item in text_store.values():\n",
    "        score = cosine_similarity(query_embedding, item[\"embedding\"]).flatten()[0]\n",
    "        text_results.append((score, item))\n",
    "    text_results = sorted(text_results, key=lambda x: x[0], reverse=True)[:top_k]\n",
    "    \n",
    "    # Retrieve image embeddings\n",
    "    image_results = []\n",
    "    for item in image_store.values():\n",
    "        score = cosine_similarity(query_embedding, item[\"embedding\"]).flatten()[0]\n",
    "        image_results.append((score, item))\n",
    "    image_results = sorted(image_results, key=lambda x: x[0], reverse=True)[:top_k]\n",
    "    \n",
    "    # Format the results\n",
    "    relevant_texts = [item[1] for item in text_results]\n",
    "    relevant_images = [item[1][\"metadata\"][\"source\"] for item in image_results]\n",
    "    \n",
    "    return relevant_texts, relevant_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade gradio\n",
    "%pip install SpeechRecognition\n",
    "%pip install gTTS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import tempfile\n",
    "# Ensure `ask_agent` is imported from the correct location\n",
    "\n",
    "# Convert audio to text using Google Speech Recognition\n",
    "def audio_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio_data)\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            return \"Sorry, I could not understand the audio.\"\n",
    "        except sr.RequestError:\n",
    "            return \"Could not request results; check your internet connection.\"\n",
    "\n",
    "# Convert text to speech using gTTS\n",
    "def text_to_speech_g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import gradio as gr\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import tempfile\n",
    "from main import ask_agent  # Import the ask_agent function\n",
    "\n",
    "# Convert audio to text using Google Speech Recognition\n",
    "def audio_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio_data)\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            return \"Sorry, I could not understand the audio.\"\n",
    "        except sr.RequestError:\n",
    "            return \"Could not request results; check your internet connection.\"\n",
    "\n",
    "# Convert text to speech using gTTS\n",
    "def text_to_speech_gtts(text):\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as fp:\n",
    "        tts.save(fp.name)\n",
    "        return fp.name\n",
    "\n",
    "# Handle user input for Gradio interface\n",
    "def handle_input(input_text=None, audio_file=None):\n",
    "    # Transcribe audio if provided, otherwise use text input\n",
    "    if audio_file is not None:\n",
    "        transcribed_text = audio_to_text(audio_file)\n",
    "        if transcribed_text.startswith(\"Sorry\"):\n",
    "            return transcribed_text, None  # Handle failed transcription\n",
    "    else:\n",
    "        transcribed_text = input_text  # Use provided text input if no audio\n",
    "\n",
    "    # Process the input using ask_agent\n",
    "    response_text = ask_agent(transcribed_text, user_id=\"default_user\")\n",
    "    \n",
    "    # Convert response to audio\n",
    "    audio_response = text_to_speech_gtts(response_text)\n",
    "    return response_text, audio_response\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=handle_input,\n",
    "    inputs=[\n",
    "        gr.Textbox(placeholder=\"Type your question here...\", label=\"Text Input\"),\n",
    "        gr.Audio(type=\"filepath\", label=\"Or speak your question\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Cat Expert's Response\"),\n",
    "        gr.Audio(label=\"Spoken Response\")\n",
    "    ],\n",
    "    title=\"Cat Behavior Expert Chatbot\",\n",
    "    description=\"Ask questions about cat behavior, either by typing or speaking.\",\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
